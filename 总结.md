# 语言基础
## C++
文章：https://github.com/linw7/Skill-Tree/blob/master/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80C%2B%2B.md
### 编程语言(C/C++)

> 都是语言，为什么英语比C++难这么多呢？

---

### 目录

| Chapter 1 | Chapter 2 | Chapter 3| Chapter 4 | 
| :---------: | :---------: | :---------: | :---------: | 
| [编程基础](base)|[面向对象基础](#oop)|[标准模板库](#stl)|[编译及调试](#other)|

---

### 内容

##### <span id = "base">编程基础</span>

C/C++的内容又多又杂，常常看到有人罗列相关书单，觉得毫无意义，我不相信他们真的完全掌握了其中任何一本。学习任何东西，首先要掌握基本概念，基础不牢地动山摇，因为高级的内容都是通过低级的概念来描述的。当基本概念都没理解透，学习再多都是空中楼阁。这里罗列了一些听基本的问题，虽然看着不难，但是精确理解每句话中的每个词真的并不容易。

1. 变量声明和定义区别？

    - 声明仅仅是把变量的声明的位置及类型提供给编译器，并不分配内存空间；定义要在定义的地方为其分配存储空间。
   
    - 相同变量可以再多处声明（外部变量extern），但只能在一处定义。

2. "零值比较"？
    - bool类型：if(flag)
    
    - int类型：if(flag == 0)
    
    - 指针类型：if(flag == null)
    
    - float类型：if((flag >= -0.000001) && (flag <= 0. 000001))

3. strlen和sizeof区别？
    - sizeof是运算符，并不是函数，结果在编译时得到而非运行中获得；strlen是字符处理的库函数。
    
    - sizeof参数可以是任何数据的类型或者数据（sizeof参数不退化）；strlen的参数只能是字符指针且结尾是'\0'的字符串。

    - **因为sizeof值在编译时确定，所以不能用来得到动态分配（运行时分配）存储空间的大小。**

4. 同一不同对象可以互相赋值吗？
    - 可以，但含有指针成员时需要注意。
    
    - 对比类的对象赋值时深拷贝和浅拷贝。

5. 结构体内存对齐问题？
    - 结构体内成员按照声明顺序存储，第一个成员地址和整个结构体地址相同。
    
    - 未特殊说明时，按结构体中size最大的成员对齐（若有double成员），按8字节对齐。

6. static作用是什么？在C和C++中有何区别？
    - static可以修饰局部变量（静态局部变量）、全局变量（静态全局变量）和函数，被修饰的变量存储位置在静态区。对于静态局部变量，相对于一般局部变量其生命周期长，直到程序运行结束而非函数调用结束，且只在第一次被调用时定义；对于静态全局变量，相对于全局变量其可见范围被缩小，只能在本文件中可见；修饰函数时作用和修饰全局变量相同，都是为了限定访问域。
    
    - C++的static除了上述两种用途，还可以修饰类成员（静态成员变量和静态成员函数），静态成员变量和静态成员函数不属于任何一个对象，是所有类实例所共有。
    
    - static的数据记忆性可以满足函数在不同调用期的通信，也可以满足同一个类的多个实例间的通信。
    
    - 未初始化时，static变量默认值为0。

7. 结构体和类的区别？
    - 结构体的默认限定符是public；类是private。
    
    - ~~结构体不可以继承，类可以。~~ C++中结构体也可以继承。

8. malloc和new的区别？
    - malloc和free是标准库函数，支持覆盖；new和delete是运算符，并且支持重载。
    
    - malloc仅仅分配内存空间，free仅仅回收空间，不具备调用构造函数和析构函数功能，用malloc分配空间存储类的对象存在风险；new和delete除了分配回收功能外，还会调用构造函数和析构函数。
    
    - malloc和free返回的是void类型指针（必须进行类型转换），new和delete返回的是具体类型指针。

9. 指针和引用区别？
    - 引用只是别名，不占用具体存储空间，只有声明没有定义；指针是具体变量，需要占用存储空间。
    
    - 引用在声明时必须初始化为另一变量，一旦出现必须为typename refname &varname形式；指针声明和定义可以分开，可以先只声明指针变量而不初始化，等用到时再指向具体变量。
    
    - 引用一旦初始化之后就不可以再改变（变量可以被引用为多次，但引用只能作为一个变量引用）；指针变量可以重新指向别的变量。
    
    - 不存在指向空值的引用，必须有具体实体；但是存在指向空值的指针。

10. 宏定义和函数有何区别？
    - 宏在编译时完成替换，之后被替换的文本参与编译，相当于直接插入了代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数。
    
    - 宏函数属于在结构中插入代码，没有返回值；函数调用具有返回值。
    
    - 宏函数参数没有类型，不进行类型检查；函数参数具有类型，需要检查类型。
    
    - 宏函数不要在最后加分号。

11. 宏定义和const区别？
    - 宏替换发生在编译阶段之前，属于文本插入替换；const作用发生于编译过程中。
    
    - 宏不检查类型；const会检查数据类型。
    
    - 宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间。

12. 宏定义和typedef区别？
    - 宏主要用于定义常量及书写复杂的内容；typedef主要用于定义类型别名。
    
    - 宏替换发生在编译阶段之前，属于文本插入替换；typedef是编译的一部分。
    
    - 宏不检查类型；typedef会检查数据类型。
    
    - 宏不是语句，不在在最后加分号；typedef是语句，要加分号标识结束。
    
    - 注意对指针的操作，typedef char * p_char和#define p_char char *区别巨大。

13. 宏定义和内联函数(inline)区别？
    - 在使用时，宏只做简单字符串替换（编译前）。而内联函数可以进行参数类型检查（编译时），且具有返回值。
    
    - 内联函数本身是函数，强调函数特性，具有重载等功能。
    
    - 内联函数可以作为某个类的成员函数，这样可以使用类的保护成员和私有成员。而当一个表达式涉及到类保护成员或私有成员时，宏就不能实现了。

14. 条件编译#ifdef, #else, #endif作用？
    - 可以通过加#define，并通过#ifdef来判断，将某些具体模块包括进要编译的内容。
    
    - 用于子程序前加#define DEBUG用于程序调试。
    
    - 应对硬件的设置（机器类型等）。
    
    - 条件编译功能if也可实现，但条件编译可以减少被编译语句，从而减少目标程序大小。

15. 区别以下几种变量？

        const int a;
        int const a;
        const int *a;
        int *const a;

    - int const a和const int a均表示定义常量类型a。
    
    - const int *a，其中a为指向int型变量的指针，const在 * 左侧，表示a指向不可变常量。(看成const (*a)，对引用加const)
    
    - int *const a，依旧是指针类型，表示a为指向整型数据的常指针。(看成const(a)，对指针const)

16. volatile有什么作用？
    - volatile定义变量的值是易变的，每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份。
    
    - 多线程中被几个任务共享的变量需要定义为volatile类型。

17. 什么是常引用？
    - 常引用可以理解为常量指针，形式为const typename & refname = varname。
    
    - 常引用下，原变量值不会被别名所修改。
    
    - 原变量的值可以通过原名修改。
    
    - 常引用通常用作只读变量别名或是形参传递。

18. 区别以下指针类型？

        int *p[10]
        int (*p)[10]
        int *p(int)
        int (*p)(int)

    - int *p[10]表示指针数组，强调数组概念，是一个数组变量，数组大小为10，数组内每个元素都是指向int类型的指针变量。
    
    - int (*p)[10]表示数组指针，强调是指针，只有一个变量，是指针类型，不过指向的是一个int类型的数组，这个数组大小是10。
    
    - int *p(int)是函数声明，函数名是p，参数是int类型的，返回值是int *类型的。
    
    - int (*p)(int)是函数指针，强调是指针，该指针指向的函数具有int类型参数，并且返回值是int类型的。

19. 常量指针和指针常量区别？
    - 常量指针是一个指针，读成常量的指针，指向一个只读变量。如int const *p或const int *p。
    
    - 指针常量是一个不能给改变指向的指针。如int *const p。

20. a和&a有什么区别？

        假设数组int a[10];
        int (*p)[10] = &a;

    - a是数组名，是数组首元素地址，+1表示地址值加上一个int类型的大小，如果a的值是0x00000001，加1操作后变为0x00000005。*(a + 1) = a[1]。
    
    - &a是数组的指针，其类型为int (*)[10]（就是前面提到的数组指针），其加1时，系统会认为是数组首地址加上整个数组的偏移（10个int型变量），值为数组a尾元素后一个元素的地址。
    
    - 若(int *)p ，此时输出 *p时，其值为a[0]的值，因为被转为int *类型，解引用时按照int类型大小来读取。

21. 数组名和指针（这里为指向数组首元素的指针）区别？
    - 二者均可通过增减偏移量来访问数组中的元素。

    - 数组名不是真正意义上的指针，可以理解为常指针，所以数组名没有自增、自减等操作。
    
    - 当数组名当做形参传递给调用函数后，就失去了原有特性，退化成一般指针，多了自增、自减操作，但sizeof运算符不能再得到原数组的大小了。

22. 野指针是什么？
    - 也叫空悬指针，不是指向null的指针，是指向垃圾内存的指针。
    
    - 产生原因及解决办法：
         - 指针变量未及时初始化 => 定义指针变量及时初始化，要么置空。
    
         - 指针free或delete之后没有及时置空 => 释放操作后立即置空。

23. 堆和栈的区别？

    - 申请方式不同。

        - 栈由系统自动分配。

        - 堆由程序员手动分配。

    - 申请大小限制不同。

        - 栈顶和栈底是之前预设好的，大小固定，可以通过ulimit -a查看，由ulimit -s修改。

        - 堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

    - 申请效率不同。

        - 栈由系统分配，速度快，不会有碎片。

        - 堆由程序员分配，速度慢，且会有碎片。

24. delete和delete[]区别？

    - delete只会调用一次析构函数。

    - delete[]会调用数组中每个元素的析构函数。


##### <span id = "oop">面向对象基础</span>

能够准确理解下面这些问题是从C程序员向C++程序员进阶的基础。当然了，这只是一部分。

1. 面向对象三大特性？

    - 封装性：数据和代码捆绑在一起，避免外界干扰和不确定性访问。
    
    - 继承性：让某种类型对象获得另一个类型对象的属性和方法。
    
    - 多态性：同一事物表现出不同事物的能力，即向不同对象发送同一消息，不同的对象在接收时会产生不同的行为（重载实现编译时多态，虚函数实现运行时多态）。

2. public/protected/private的区别？
    - public的变量和函数在类的内部外部都可以访问。
    
    - protected的变量和函数只能在类的内部和其派生类中访问。
    
    - private修饰的元素只能在类内访问。

3. 对象存储空间？
    - 非静态成员的数据类型大小之和。
    
    - 编译器加入的额外成员变量（如指向虚函数表的指针）。
    
    - 为了边缘对齐优化加入的padding。

4. C++空类有哪些成员函数?
    - 首先，空类大小为1字节。
    
    - 默认函数有：
        - 构造函数
    
        - 析构函数
    
        - 拷贝构造函数
    
        - 赋值运算符

5. 构造函数能否为虚函数，析构函数呢？
    - 析构函数：
        - 析构函数可以为虚函数，并且一般情况下基类析构函数要定义为虚函数。
    
        - 只有在基类析构函数定义为虚函数时，调用操作符delete销毁指向对象的基类指针时，才能准确调用派生类的析构函数（从该级向上按序调用虚函数），才能准确销毁数据。
    
        - 析构函数可以是纯虚函数，含有纯虚函数的类是抽象类，此时不能被实例化。但派生类中可以根据自身需求重新改写基类中的纯虚函数。
    
    - 构造函数：
        - 构造函数不能定义为虚函数。在构造函数中可以调用虚函数，不过此时调用的是正在构造的类中的虚函数，而不是子类的虚函数，因为此时子类尚未构造好。

6. 构造函数调用顺序，析构函数呢？
    - 调用所有虚基类的构造函数，顺序为从左到右，从最深到最浅

    - 基类的构造函数：如果有多个基类，先调用纵向上最上层基类构造函数，如果横向继承了多个类，调用顺序为派生表从左到右顺序。
    
    - 如果该对象需要虚函数指针(vptr)，则该指针会被设置从而指向对应的虚函数表(vtbl)。
    
    - 成员类对象的构造函数：如果类的变量中包含其他类（类的组合），需要在调用本类构造函数前先调用成员类对象的构造函数，调用顺序遵照在类中被声明的顺序。
    
    - 派生类的构造函数。
    
    - 析构函数与之相反。

7. 拷贝构造函数中深拷贝和浅拷贝区别？
    - 深拷贝时，当被拷贝对象存在动态分配的存储空间时，需要先动态申请一块存储空间，然后逐字节拷贝内容。
    
    - 浅拷贝仅仅是拷贝指针字面值。
    
    - 当使用浅拷贝时，如果原来的对象调用析构函数释放掉指针所指向的数据，则会产生空悬指针。因为所指向的内存空间已经被释放了。

8. 拷贝构造函数和赋值运算符重载的区别？
    - 拷贝构造函数是函数，赋值运算符是运算符重载。
    
    - 拷贝构造函数会生成新的类对象，赋值运算符不能。
    
    - 拷贝构造函数是直接构造一个新的类对象，所以在初始化对象前不需要检查源对象和新建对象是否相同；赋值运算符需要上述操作并提供两套不同的复制策略，另外赋值运算符中如果原来的对象有内存分配则需要先把内存释放掉。
    
    - 形参传递是调用拷贝构造函数（调用的被赋值对象的拷贝构造函数），但并不是所有出现"="的地方都是使用赋值运算符，如下：

            Student s;
            Student s1 = s;    // 调用拷贝构造函数
            Student s2;
            s2 = s;    // 赋值运算符操作

    **注：类中有指针变量时要重写析构函数、拷贝构造函数和赋值运算符**

9. 虚函数和纯虚函数区别？
    - 虚函数是为了实现动态编联产生的，目的是通过基类类型的指针指向不同对象时，自动调用相应的、和基类同名的函数（使用同一种调用形式，既能调用派生类又能调用基类的同名函数）。虚函数需要在基类中加上virtual修饰符修饰，因为virtual会被隐式继承，所以子类中相同函数都是虚函数。当一个成员函数被声明为虚函数之后，其派生类中同名函数自动成为虚函数，在派生类中重新定义此函数时要求函数名、返回值类型、参数个数和类型全部与基类函数相同。
    
    - 纯虚函数只是相当于一个接口名，但含有纯虚函数的类不能够实例化。

10. 覆盖、重载和隐藏的区别？
     - 覆盖是派生类中重新定义的函数，其函数名、参数列表（个数、类型和顺序）、返回值类型和父类完全相同，只有函数体有区别。派生类虽然继承了基类的同名函数，但用派生类对象调用该函数时会根据对象类型调用相应的函数。覆盖只能发生在类的成员函数中。
    
     - 隐藏是指派生类函数屏蔽了与其同名的函数，这里仅要求基类和派生类函数同名即可。其他状态同覆盖。可以说隐藏比覆盖涵盖的范围更宽泛，毕竟参数不加限定。
    
     - 重载是具有相同函数名但参数列表不同（个数、类型或顺序）的两个函数（不关心返回值），当调用函数时根据传递的参数列表来确定具体调用哪个函数。重载可以是同一个类的成员函数也可以是类外函数。

11. 在main执行之前执行的代码可能是什么？

    - 全局对象的构造函数。

12. 哪几种情况必须用到初始化成员列表？

    - 初始化一个const成员。

    - 初始化一个reference成员。

    - 调用一个基类的构造函数，而该函数有一组参数。

    - 调用一个数据成员对象的构造函数，而该函数有一组参数。

13. 什么是虚指针？

    - 虚指针或虚函数指针是虚函数的实现细节。

    - 虚指针指向虚表结构。

14. 重载和函数模板的区别？

    - 重载需要多个函数，这些函数彼此之间函数名相同，但参数列表中参数数量和类型不同。在区分各个重载函数时我们并不关心函数体。

    - 模板函数是一个通用函数，函数的类型和形参不直接指定而用虚拟类型来代表。但只适用于参个数相同而类型不同的函数。

15. this指针是什么？

    - this指针是类的指针，指向对象的首地址。

    - this指针只能在成员函数中使用，在全局函数、静态成员函数中都不能用this。

    - this指针只有在成员函数中才有定义，且存储位置会因编译器不同有不同存储位置。

16. 类模板是什么？

    - 用于解决多个功能相同、数据类型不同的类需要重复定义的问题。

    - 在建立类时候使用template及任意类型标识符T，之后在建立类对象时，会指定实际的类型，这样才会是一个实际的对象。

    - 类模板是对一批仅数据成员类型不同的类的抽象，只要为这一批类创建一个类模板，即给出一套程序代码，就可以用来生成具体的类。

17. 构造函数和析构函数调用时机？

    - 全局范围中的对象：构造函数在所有函数调用之前执行，在主函数执行完调用析构函数。

    - 局部自动对象：建立对象时调用构造函数，离开作用域时调用析构函数。

    - 动态分配的对象：建立对象时调用构造函数，调用释放时调用析构函数。

    - 静态局部变量对象：建立时调用一次构造函数，主函数结束时调用析构函数。

---

##### <span id = "stl">标准模板库</span>

STL内容虽然看起来很多，单独成书都不是问题（《STL源码剖析》），但从实际使用状况来看，我认为只需要知道以下几点就可以了：

- 怎么用？

    各种STL基本的增删改查怎么使用。每种容器都提供了很多操作，但实际增删改查我们通常只需要掌握透彻一种方式即可。有些功能只是出于通用性考虑才存在的，但对于相应的STL这些操作完全可以忽略。所以我对STL使用的看法是，不需要花太多时间去了解所有功能，只要掌握最基本的即可，要把精力放在对需求的了解并选择适合的数据结构。

- 怎么实现？

    本身STL就是封装了我们常用的数据结构，所以最先需要了解每种数据结构的特性。而且了解实现方式对我们能够准确、高效使用STL打下了基础。

- 如何避免错误？

    在第二阶段了解了STL的实现之后，我们已经可以很清楚地知道他们底层使用的是什么数据结构以及该数据结构做什么操作比较高效。但还有一点需要注意的就是怎么才能用对他们，避免一些未知的错误，比如迭代器失效问题。

**string**


**vector**

用法：

        定义：
            vector<T> vec;

        插入元素：
            vec.push_back(element);
            vec.insert(iterator, element);

        删除元素：
            vec.pop_back();
            vec.erase(iterator);

        修改元素：
            vec[position] = element;

        遍历容器：
            for(auto it = vec.begin(); it != vec.end(); ++it) {......}

        其他：
            vec.empty();    //判断是否空
            vec.size();    // 实际元素
            vec.capacity();    // 容器容量
            vec.begin();    // 获得首迭代器
            vec.end();    // 获得尾迭代器
            vec.clear();    // 清空

实现：

[模拟Vector实现](https://github.com/linw7/Skill-Tree/blob/master/code/my_vector.cpp)

- 线性表，数组实现。
    - 支持随机访问。
    
    - 插入删除操作需要大量移动数据。

- 需要连续的物理存储空间。

- 每当大小不够时，重新分配内存（*2），并复制原内容。

错误避免：

[迭代器失效](https://github.com/linw7/Skill-Tree/blob/master/code/vector_iterator.cpp)

- 插入元素
    - 尾后插入：size < capacity时，首迭代器不失效尾迭代实现（未重新分配空间），size == capacity时，所有迭代器均失效（需要重新分配空间）。
    
    - 中间插入：size < capacity时，首迭代器不失效但插入元素之后所有迭代器失效，size == capacity时，所有迭代器均失效。

- 删除元素
    - 尾后删除：只有尾迭代失效。
    
    - 中间删除：删除位置之后所有迭代失效。

**map**

用法：

        定义：
            map<T_key, T_value> mymap;

        插入元素：
            mymap.insert(pair<T_key, T_value>(key, value));    // 同key不插入
            mymap.insert(map<T_key, T_value>::value_type(key, value));    // 同key不插入
            mymap[key] = value;    // 同key覆盖

        删除元素：
            mymap.erase(key);    // 按值删
            mymap.erase(iterator);    // 按迭代器删

        修改元素：
            mymap[key] = new_value;

        遍历容器：
              for(auto it = mymap.begin(); it != mymap.end(); ++it) {
                cout << it->first << " => " << it->second << '\n';
              }

实现：

[RBTree实现](https://github.com/linw7/Skill-Tree/tree/master/code/RBTree)

- 树状结构，RBTree实现。
    - 插入删除不需要数据复制。
    
    - 操作复杂度仅跟树高有关。

- RBTree本身也是二叉排序树的一种，key值有序，且唯一。
    - 必须保证key可排序。

基于红黑树实现的map结构（实际上是map, set, multimap，multiset底层均是红黑树），不仅增删数据时不需要移动数据，其所有操作都可以在O(logn)时间范围内完成。另外，基于红黑树的map在通过迭代器遍历时，得到的是key按序排列后的结果，这点特性在很多操作中非常方便。

面试时候现场写红黑树代码的概率几乎为0，但是红黑树一些基本概念还是需要掌握的。

1. 它是二叉排序树（继承二叉排序树特显）：
    - 若左子树不空，则左子树上所有结点的值均小于或等于它的根结点的值。

    - 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值。

    - 左、右子树也分别为二叉排序树。

2. 它满足如下几点要求：
    - 树中所有节点非红即黑。

    - 根节点必为黑节点。

    - 红节点的子节点必为黑（黑节点子节点可为黑）。

    - 从根到NULL的任何路径上黑结点数相同。

3. 查找时间一定可以控制在O(logn)。

4. 红黑树的节点定义如下：
    ```C++
    enum Color {
        RED = 0,
        BLACK = 1
    };
    struct RBTreeNode {
        struct RBTreeNode*left, *right, *parent;
        int key;
        int data;
        Color color;
    };
    ```
所以对红黑树的操作需要满足两点：1.满足二叉排序树的要求；2.满足红黑树自身要求。通常在找到节点通过和根节点比较找到插入位置之后，还需要结合红黑树自身限制条件对子树进行左旋和右旋。

相比于AVL树，红黑树平衡性要稍微差一些，不过创建红黑树时所需的旋转操作也会少很多。相比于最简单的BST，BST最差情况下查找的时间复杂度会上升至O(n)，而红黑树最坏情况下查找效率依旧是O(logn)。所以说红黑树之所以能够在STL及Linux内核中被广泛应用就是因为其折中了两种方案，既减少了树高，又减少了建树时旋转的次数。

从红黑树的定义来看，红黑树从根到NULL的每条路径拥有相同的黑节点数（假设为n），所以最短的路径长度为n（全为黑节点情况）。因为红节点不能连续出现，所以路径最长的情况就是插入最多的红色节点，在黑节点数一致的情况下，最可观的情况就是黑红黑红排列......最长路径不会大于2n，这里路径长就是树高。

**set**

---

##### <span id = "other">编译及调试</span>

**编译**

预处理

- 展开所有的宏定义，完成字符常量替换。

- 处理条件编译语句，通过是否具有某个宏来决定过滤掉哪些代码。

- 处理#include指令，将被包含的文件插入到该指令所在位置。

- 过滤掉所有注释语句。

- 添加行号和文件名标识。

- 保留所有#pragma编译器指令。

编译

- 词法分析。

- 语法分析。

- 语义分析。

- 中间语言生成。

- 目标代码生成与优化。

链接

各个源代码模块独立的被编译，然后将他们组装起来成为一个整体，组装的过程就是链接。被链接的各个部分本本身就是二进制文件，所以在被链接时需要将所有目标文件的代码段拼接在一起，然后将所有对符号地址的引用加以修正。

- 静态链接

    静态链接最简单的情况就是在编译时和静态库链接在一起成为完整的可执行程序。这里所说的静态库就是对多个目标文件（.o）文件的打包，通常静态链接的包名为lib****.a，静态链接所有被用到的目标文件都会复制到最终生成的可执行目标文件中。这种方式的好处是在运行时，可执行目标文件已经完全装载完毕，只要按指令序执行即可，速度比较快，但缺点也有很多，在讲动态链接时会比较一下。

    既然静态链接是对目标文件的打包，这里介绍些打包命令。

        gcc -c test1.c    // 生成test1.o
        gcc -c test2.c    // 生成test2.c
        ar cr libtest.a test1.o test2.o

    首先编译得到test1.o和test2.o两个目标文件，之后通过ar命令将这两个文件打包为.a文件，文件名格式为lib + 静态库名 + .a后缀。在生成可执行文件需要使用到它的时候只需要在编译时加上即可。需要注意的是，使用静态库时加在最后的名字不是libtest.a，而是l + 静态库名。

        gcc -o main main.c -ltest

- 动态链接

    静态链接发生于编译阶段，加载至内存前已经完整，但缺点是如果多个程序都需要使用某个静态库，则该静态库会在每个程序中都拷贝一份，非常浪费内存资源，所以出现了动态链接的方式来解决这个问题。

    动态链接在形式上倒是和静态链接非常相似，首先也是需要打包，打包成动态库，不过文件名格式为lib + 动态库名 + .so后缀。不过动态库的打包不需要使用ar命令，gcc就可以完成，但要注意在编译时要加上-fPIC选项，打包时加上-shared选项。

        gcc -fPIC -c test1.c 
        gcc -fPIC -c test2.c
        gcc -shared test1.o test2.o -o libtest.so

    使用动态链接的用法也和静态链接相同。

        gcc -o main main.c -ltest

如果仅仅像上面的步骤是没有办法正常使用库的，我们可以通过加-Lpath指定搜索库文件的目录（-L.表示当前目录），默认情况下会到环境变量LD_LIBRARY_PATH指定的目录下搜索库文件，默认情况是/usr/lib，我们可以将库文件拷贝到那个目录下再链接。

比较静态库和动态库我们可以得到二者的优缺点。

- 动态库运行时会先检查内存中是否已经有该库的拷贝，若有则共享拷贝，否则重新加载动态库（C语言的标准库就是动态库）。静态库则是每次在编译阶段都将静态库文件打包进去，当某个库被多次引用到时，内存中会有多份副本，浪费资源。

- 动态库另一个有点就是更新很容易，当库发生变化时，如果接口没变只需要用新的动态库替换掉就可以了。但是如果是静态库的话就需要重新被编译。

- 不过静态库也有优点，主要就是静态库一次性完成了所有内容的绑定，运行时就不必再去考虑链接的问题了，执行效率会稍微高一些。

makefile编写

对于大的工程通常涉及很多头文件和源文件，编译起来很很麻烦，makefile正是为了自动化编译产生的，makefile像是编译说明书，指示编译的步骤和条件，之后被make命令解释。

- 基本规则

        A:B
        (tab)<command>

    其中A是语句最后生成的文件，B是生成A所依赖的文件，比如生成test.o依赖于test.c和test.h，则写成test.o:test.c test.h。接下来一行的开头必须是tab，再往下就是实际的命令了，比如gcc -c test.c -o test.o。

- 变量

    makefile的书写非常像shell脚本，可以在文件中定义"变量名 = 变量值"的形式，之后需要使用这个变量时只需要写一个$符号加上变量名即可，当然，和shell一样，最好用()包裹起语句来。

**链接**

符号解析

- 可重定位目标文件

    对于独立编译的可重定位目标文件，其ELF文件格式包括ELF头（指定文件大小及字节序）、.text（代码段）、.rodata（只读数据区）、.data（已初始化数据区）、.bss（未初始化全局变量）、.symtab（符号表）等，其中链接时最需要关注的就是符号表。每个可重定位目标文件都有一张符号表，它包含该模块定义和引用的符号的信息，简而言之就是我们在每个模块中定义和引用的全局变量（包括定义在本模块的全局变量、静态全局变量和引用自定义在其他模块的全局变量）需要通过一张表来记录，在链接时通过查表将各个独立的目标文件合并成一个完整的可执行文件。

- 解析符号表

    解析符号引用的目的是将每个引用与可重定位目标文件的符号表中的一个符号定义联系起来。

重定位

- 合并节

    多个可重定位目标文件中相同的节合并成一个完整的聚合节，比如多个目标文件的.data节合并成可执行文件的.data节。链接器将运行时存储地址赋予每个节，完成这步每条指令和全局变量都有运行时地址了。

- 重定位符号引用

    这步修改全部代码节和数据节对每个符号的符号引用，使其指向正确的运行时地址。局部变量可以通过进栈、出栈临时分配，但全局变量（"符号"）的位置则是在各个可重定位目标文件中预留好的。通过上一步合并节操作后，指令中所有涉及符号的引用都会通过一定的寻址方式来定位该符号，比如相对寻址、绝对寻址等。

可执行目标文件

- ELF头部

    描述文件总体格式，并且包括程序的入口点（entry point），也就是程序运行时执行的第一条指令地址。

- 段头部表

    描述了可执行文件数据段、代码段等各段的大小、虚拟地址、段对齐、执行权限等。实际上通过段头部表描绘了虚拟存储器运行时存储映像，比如每个UNIX程序的代码段总是从虚拟地址Ox0804800开始的。

- 其他段

    和可重定位目标文件各段基本相同，但完成了多个节的合并和重定位工作。

加载

- 克隆

    新程序的执行首先需要通过父进程外壳通过fork得到一个子进程，该子进程除了pid等标识和父进程不同外其他基本均与父进程相同。

- 重新映射

    当子进程执行execve系统调用时会先清空子进程现有的虚拟存储器段（简而言之就是不再映射到父进程的各个段），之后重新创建子进程虚拟存储器各段和可执行目标文件各段的映射。这个阶段我们可以理解为对复制来的父进程页表进程重写，映射到外存中可执行文件的各个段。

- 虚页调入

    加载过程并没有实际将磁盘中可执行文件调入内存，所做的工作紧紧是复制父进程页表、清空旧页表、建立新页表映射工作。之后加载器跳转到入口地址_start开始执行程序，接下来的过程需要配合虚拟存储器来完成。CPU获得指令的虚拟地址后，若包含该指令或数据的页尚未调入内存则将其从外存中调入，调入内存后修改页表得到虚拟页号和物理页号的对应关系。之后重新取同一条指令或数据时因该页已经被调入内存，所以通过虚拟地址得到虚拟页号，虚拟页号通过查页表可以得到物理页号，通过物理页号 + 页内偏移得到具体的物理地址，此时可以通过物理地址取得想要的数据。

## Python
## Go

# 计算机网络
## 七层网络协议与五层网络协议
一、OSI七层模型
OSI七层协议模型主要是：应用层（Application）、表示层（Presentation）、会话层（Session）、传输层（Transport）、网络层（Network）、数据链路层（Data Link）、物理层（Physical）。

三、五层体系结构
五层体系结构包括：应用层、运输层、网络层、数据链路层和物理层。 
五层协议只是OSI和TCP/IP的综合，实际应用还是TCP/IP的四层结构。为了方便可以把下两层称为网络接口层。
![](../picg/20170822222325781.png)
![](../picg/20170822224933262.png)
## TCP/Ip
TCP 文章：https://www.bookstack.cn/read/cpp-interview/spilt.8.README.md
TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议，其传输的单位是报文段。
特征：

- 面向连接
- 只能点对点（一对一）通信
- 可靠交互
- 全双工通信
- 面向字节流

TCP 如何保证可靠传输：
- 确认和超时重传
- 数据合理分片和排序
- 流量控制
- 拥塞控制
- 数据校验

**TCP 报文结构**
![](../picg/TCP报文.png)
**TCP首部**
![](../picg/TCP首部.png)

TCP：状态控制码（Code，Control Flag），占 6 比特，含义如下：
- URG：紧急比特（urgent），当 URG＝1 时，表明紧急指针字段有效，代表该封包为紧急封包。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)， 且上图中的 Urgent Pointer 字段也会被启用。
- ACK：确认比特（Acknowledge）。只有当 ACK＝1 时确认号字段才有效，代表这个封包为确认封包。当 ACK＝0 时，确认号无效。
- PSH：（Push function）若为 1 时，代表要求对方立即传送缓冲区内的其他对应封包，而无需等缓冲满了才送。
- RST：复位比特(Reset)，当 RST＝1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。
- SYN：同步比特(Synchronous)，SYN 置为 1，就表示这是一个连接请求或连接接受报文，通常带有 SYN 标志的封包表示『主动』要连接到对方的意思。
- FIN：终止比特(Final)，用来释放一个连接。当 FIN＝1 时，表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。

**UDP**
UDP（User Datagram Protocol，用户数据报协议）是 OSI（Open System Interconnection 开放式系统互联） 参考模型中一种无连接的传输层协议，提供**面向事务**的简单不可靠信息传送服务，其传输的单位是用户**数据报**。

特征：

1、无连接
2、尽最大努力交付
3、面向报文
4、没有拥塞控制
5、支持一对一、一对多、多对一、多对多的交互通信
6、首部开销小

UDP 报文结构
![](../picg/UDP报文.png)

UDP 首部
![](../picg/UDP首部.png)

### TCP 与 UDP 的区别
1、TCP 面向连接，UDP 是无连接的；
2、TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付
3、TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道
4、每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信
5、TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）
6、UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）
7、TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节

### TCP 黏包问题
**原因**
TCP 是一个基于字节流的传输服务（UDP 基于报文的），“流” 意味着 TCP 所传输的数据是没有边界的。所以可能会出现两个数据包黏在一起的情况。

**解决**
- 发送定长包。如果每个消息的大小都是一样的，那么在接收对等方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。
- 包头加上包体长度。包头是定长的 4 个字节，说明了包体的长度。接收对等方先接收包头长度，依据包头长度来接收包体。
- 在数据包之间设置边界，如添加特殊符号 \r\n 标记。FTP 协议正是这么做的。但问题在于如果数据正文中也含有 \r\n，则会误判为消息的边界。
- 使用更加复杂的应用层协议。

### TCP 流量控制
**概念**
流量控制（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。
**方法**
利用可变窗口进行流量控制
![](../picg/利用可变窗口进行流量控制举例.png)

### <span id = "trans">传输层(TCP/UDP)</span>

1. ISO七层模型中表示层和会话层功能是什么？
    - 表示层：图像、视频编码解，数据加密。

    - 会话层：建立会话，如session认证、断点续传。

2. 描述TCP头部？
    - 序号（32bit）：传输方向上字节流的字节编号。初始时序号会被设置一个随机的初始值（ISN），之后每次发送数据时，序号值 = ISN + 数据在整个字节流中的偏移。假设A -> B且ISN = 1024，第一段数据512字节已经到B，则第二段数据发送时序号为1024 + 512。用于解决网络包乱序问题。
    
    - 确认号（32bit）：接收方对发送方TCP报文段的响应，其值是收到的序号值 + 1。
    
    - 首部长（4bit）：标识首部有多少个4字节 * 首部长，最大为15，即60字节。
    
    - 标志位（6bit）：
        - URG：标志紧急指针是否有效。
        
        - ACK：标志确认号是否有效（确认报文段）。用于解决丢包问题。
        
        - PSH：提示接收端立即从缓冲读走数据。
        
        - RST：表示要求对方重新建立连接（复位报文段）。
        
        - SYN：表示请求建立一个连接（连接报文段）。
        
        - FIN：表示关闭连接（断开报文段）。
    
    - 窗口（16bit）：接收窗口。用于告知对方（发送方）本方的缓冲还能接收多少字节数据。用于解决流控。
    
    - 校验和（16bit）：接收端用CRC检验整个报文段有无损坏。

3. 三次握手过程？
    - 第一次：客户端发含SYN位，SEQ_NUM = S的包到服务器。（客 -> SYN_SEND）
    
    - 第二次：服务器发含ACK，SYN位且ACK_NUM = S + 1，SEQ_NUM = P的包到客户机。（服 -> SYN_RECV）
    
    - 第三次：客户机发送含ACK位，ACK_NUM = P + 1的包到服务器。（客 -> ESTABLISH，服 -> ESTABLISH）

4. 四次挥手过程？
    - 第一次：客户机发含FIN位，SEQ = Q的包到服务器。（客 -> FIN_WAIT_1）
    
    - 第二次：服务器发送含ACK且ACK_NUM = Q + 1的包到服务器。（服 -> CLOSE_WAIT，客 -> FIN_WAIT_2）
        - 此处有等待
    
    - 第三次：服务器发送含FIN且SEQ_NUM = R的包到客户机。（服 -> LAST_ACK，客 -> TIME_WAIT）
        - 此处有等待
    
    - 第四次：客户机发送最后一个含有ACK位且ACK_NUM = R + 1的包到客户机。（服 -> CLOSED）

5. 为什么握手是三次，挥手是四次？
    - 对于握手：握手只需要确认双方通信时的初始化序号，保证通信不会乱序。（第三次握手必要性：假设服务端的确认丢失，连接并未断开，客户机超时重发连接请求，这样服务器会对同一个客户机保持多个连接，造成资源浪费。）
    
    - 对于挥手：TCP是双工的，所以发送方和接收方都需要FIN和ACK。只不过有一方是被动的，所以看上去就成了4次挥手。

6. TCP连接状态？
    - CLOSED：初始状态。
    
    - LISTEN：服务器处于监听状态。
    
    - SYN_SEND：客户端socket执行CONNECT连接，发送SYN包，进入此状态。
    
    - SYN_RECV：服务端收到SYN包并发送服务端SYN包，进入此状态。
    
    - ESTABLISH：表示连接建立。客户端发送了最后一个ACK包后进入此状态，服务端接收到ACK包后进入此状态。
    
    - FIN_WAIT_1：终止连接的一方（通常是客户机）发送了FIN报文后进入。等待对方FIN。
    
    - CLOSE_WAIT：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本方是否立即断开连接（发送FIN包）取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。
    
    - FIN_WAIT_2：此时是半连接状态，即有一方要求关闭连接，等待另一方关闭。客户端接收到服务器的ACK包，但并没有立即接收到服务端的FIN包，进入FIN_WAIT_2状态。
    
    - LAST_ACK：服务端发动最后的FIN包，等待最后的客户端ACK响应，进入此状态。
    
    - TIME_WAIT：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，在此之后的2MSL时间称为TIME_WAIT状态。

7. 解释FIN_WAIT_2，CLOSE_WAIT状态和TIME_WAIT状态？
    - FIN_WAIT_2：
        - 半关闭状态。
        
        - 发送断开请求一方还有接收数据能力，但已经没有发送数据能力。
    
    - CLOSE_WAIT状态：
        - 被动关闭连接一方接收到FIN包会立即回应ACK包表示已接收到断开请求。
        
        - 被动关闭连接一方如果还有剩余数据要发送就会进入CLOSED_WAIT状态。
    
    - TIME_WAIT状态：
        - 又叫2MSL等待状态。
        
        - 如果客户端直接进入CLOSED状态，如果服务端没有接收到最后一次ACK包会在超时之后重新再发FIN包，此时因为客户端已经CLOSED，所以服务端就不会收到ACK而是收到RST。所以TIME_WAIT状态目的是防止最后一次握手数据没有到达对方而触发重传FIN准备的。
        
        - 在2MSL时间内，同一个socket不能再被使用，否则有可能会和旧连接数据混淆（如果新连接和旧连接的socket相同的话）。

8. 解释RTO，RTT和超时重传？
    - 超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：
        
        - 发送的数据没能到达接收端，所以对方没有响应。
        
        - 接收端接收到数据，但是ACK报文在返回过程中丢失。
        
        - 接收端拒绝或丢弃数据。
    
    - RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。
        - 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......
        
        - 重传次数到达上限之后停止重传。
    
    - RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。

9. 流量控制原理？
    - 目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。所以流量控制是点对点控制。

    - TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。

        - 发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。

        - 接收窗：用来标记可以接收的数据大小。

    - TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分。

    - 发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

10. 拥塞控制原理？
    - 拥塞控制目的是防止数据被过多注网络中导致网络资源（路由器、交换机等）过载。因为拥塞控制涉及网络链路全局，所以属于全局控制。控制拥塞使用拥塞窗口。

    - TCP拥塞控制算法：
        - 慢开始 & 拥塞避免：先试探网络拥塞程度再逐渐增大拥塞窗口。每次收到确认后拥塞窗口翻倍，直到达到阀值ssthresh，这部分是慢开始过程。达到阀值后每次以一个MSS为单位增长拥塞窗口大小，当发生拥塞（超时未收到确认），将阀值减为原先一半，继续执行线性增加，这个过程为拥塞避免。
        
        - 快速重传 & 快速恢复：略。

        - 最终拥塞窗口会收敛于稳定值。

11. 如何区分流量控制和拥塞控制？
    - 流量控制属于通信双方协商；拥塞控制涉及通信链路全局。

    - 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。

    - 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。

12. TCP如何提供可靠数据传输的？
    - 建立连接（标志位）：通信前确认通信实体存在。
    
    - 序号机制（序号、确认号）：确保了数据是按序、完整到达。
    
    - 数据校验（校验和）：CRC校验全部数据。
    
    - 超时重传（定时器）：保证因链路故障未能到达数据能够被多次重发。
    
    - 窗口机制（窗口）：提供流量控制，避免过量发送。
    
    - 拥塞控制：同上。

13. TCP soctet交互流程？
    - 服务器：
        - 创建socket -> int socket(int domain, int type, int protocol);
            - domain：协议域，决定了socket的地址类型，IPv4为AF_INET。
      
            - type：指定socket类型，SOCK_STREAM为TCP连接。
      
            - protocol：指定协议。IPPROTO_TCP表示TCP协议，为0时自动选择type默认协议。
      
        - 绑定socket和端口号 -> int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
            - sockfd：socket返回的套接字描述符，类似于文件描述符fd。
      
            - addr：有个sockaddr类型数据的指针，指向的是被绑定结构变量。
            ```C++
                // IPv4的sockaddr地址结构
                struct sockaddr_in {
                    sa_family_t sin_family;    // 协议类型，AF_INET
                    in_port_t sin_port;    // 端口号
                    struct in_addr sin_addr;    // IP地址
                };
                struct in_addr {
                    uint32_t s_addr;
                }
            ```
      
            - addrlen：地址长度。
      
        - 监听端口号 -> int listen(int sockfd, int backlog);
            - sockfd：要监听的sock描述字。
      
            - backlog：socket可以排队的最大连接数。
      
        - 接收用户请求 -> int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
            - sockfd：服务器socket描述字。
      
            - addr：指向地址结构指针。
      
            - addrlen：协议地址长度。
      
            - 注：一旦accept某个客户机请求成功将返回一个全新的描述符用于标识具体客户的TCP连接。
      
        - 从socket中读取字符 -> ssize_t read(int fd, void *buf, size_t count);
            - fd：连接描述字。
      
            - buf：缓冲区buf。
      
            - count：缓冲区长度。
      
            - 注：大于0表示读取的字节数，返回0表示文件读取结束，小于0表示发生错误。
        
        - 关闭socket -> int close(int fd);
        
            - fd：accept返回的连接描述字，每个连接有一个，生命周期为连接周期。
        
            - 注：sockfd是监听描述字，一个服务器只有一个，用于监听是否有连接；fd是连接描述字，用于每个连接的操作。
    
    - 客户机：
        - 创建socket -> int socket(int domain, int type, int protocol);
    
        - 连接指定计算机 -> int connect(int sockfd, struct sockaddr* addr, socklen_t addrlen);
            - sockfd客户端的sock描述字。
    
            - addr：服务器的地址。
    
            - addrlen：socket地址长度。
    
        - 向socket写入信息 -> ssize_t write(int fd, const void *buf, size_t count);
            - fd、buf、count：同read中意义。
    
            - 大于0表示写了部分或全部数据，小于0表示出错。
    
        - 关闭oscket -> int close(int fd);
            - fd：同服务器端fd。
文章来源：https://github.com/linw7/Skill-Tree/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#trans

---
### TCP 有限状态机
![](../picg/TCP的有限状态机.png)
## socket
### tcp面试问题及答案
1、如果已经建立了连接，但是客户端突然出现故障了怎么办？
> TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。
2、为什么客户端最后还要等待2MSL？
> MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。
第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。
3、为什么TCP客户端最后还要发送一次确认呢？
> 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。
如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。
如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。
4、如果客户端不断的发送请求连接会怎样?
> • 服务器端会为每个请求创建一个链接，然后向client端发送创建链接时的回复，然后进行等待客户端发送第三次握手数据包，这样会白白浪费资源
• DDos攻击
简单的说就是想服务器发送链接请求，首先进行
第一步:客户端向服务器端发送连接请求数据包(1)    第二步:服务器向客户端回复连接请求数据包(2)，然后服务器等待客户端发送tcp/ip链接的第三步数据包(3)    第三步:如果客户端不向服务器端发送最后一个数据包(3)，则服务器须等30s到2min中才能将此链接进行关闭。当大量的请求只进行到第二步，而不进行第三步，服务器又大量的资源等待第三个数据包。则造成DDos攻击。
• DDos预防(没有根治的办法，除非不用TCP/IP链接)、
• 确保服务器的系统文件是最新版本，并及时更新系统补丁
• 关闭不必要的服务
• 限制同时打开SYN的半连接数目
• 缩短SYN半连接的time out时间
• 正确设置防火墙
• 禁止对主机的非开放服务的访问
• 限制特定IP短地址的访问
• 启用防火墙的防DDos的属性
• 严格限制对外开放的服务器的向外访问
• 运行端口映射程序祸端口扫描程序，要认真检查特权端口和非特权端口。
• 认真检查网络设备和主机/服务器系统的日志。只要日志出现漏洞或是时间变更，那这台机器就可能遭到了攻击。
• 限制在防火墙外与网络文件共享。这样会给黑客截取系统文件的机会，主机的信息暴露给黑客，无疑是给了对方入侵的机会。

5、为什么TCP连接需要三次握手，两次不可以吗，为什么
> • 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。
• 例子
“已失效的连接请求报文段”的产生在这样一种情况下:client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。     于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”


## HTTP/HTTPS
文章来源：https://github.com/CyC2018/CS-Notes/blob/master/notes/HTTP.md
### 一 、基础概念

#### URI

URI 包含 URL 和 URN。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/8441b2c4-dca7-4d6b-8efb-f22efccaf331.png" width="500px"> </div><br>

#### 请求和响应报文

##### 1. 请求报文

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP_RequestMessageExample.png" width=""/> </div><br>

##### 2. 响应报文

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP_ResponseMessageExample.png" width=""/> </div><br>

### 二、HTTP 方法

客户端发送的   **请求报文**   第一行为请求行，包含了方法字段。

#### GET

> 获取资源

当前网络请求中，绝大部分使用的是 GET 方法。

#### HEAD

> 获取报文首部

和 GET 方法类似，但是不返回报文实体主体部分。

主要用于确认 URL 的有效性以及资源更新的日期时间等。

#### POST

> 传输实体主体

POST 主要用来传输数据，而 GET 主要用来获取资源。

更多 POST 与 GET 的比较请见第九章。

#### PUT

> 上传文件

由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。

```html
PUT /new.html HTTP/1.1
Host: example.com
Content-type: text/html
Content-length: 16

<p>New File</p>
```

#### PATCH

> 对资源进行部分修改

PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。

```html
PATCH /file.txt HTTP/1.1
Host: www.example.com
Content-Type: application/example
If-Match: "e0023aa4e"
Content-Length: 100

[description of changes]
```

#### DELETE

> 删除文件

与 PUT 功能相反，并且同样不带验证机制。

```html
DELETE /file.html HTTP/1.1
```

#### OPTIONS

> 查询支持的方法

查询指定的 URL 能够支持的方法。

会返回 `Allow: GET, POST, HEAD, OPTIONS` 这样的内容。

#### CONNECT

> 要求在与代理服务器通信时建立隧道

使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。

```html
CONNECT www.example.com:443 HTTP/1.1
```

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/dc00f70e-c5c8-4d20-baf1-2d70014a97e3.jpg" width=""/> </div><br>

#### TRACE

> 追踪路径

服务器会将通信路径返回给客户端。

发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。

通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。

### 三、HTTP 状态码

服务器返回的   **响应报文**   中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。

| 状态码 | 类别 | 含义 |
| :---: | :---: | :---: |
| 1XX | Informational（信息性状态码） | 接收的请求正在处理 |
| 2XX | Success（成功状态码） | 请求正常处理完毕 |
| 3XX | Redirection（重定向状态码） | 需要进行附加操作以完成请求 |
| 4XX | Client Error（客户端错误状态码） | 服务器无法处理请求 |
| 5XX | Server Error（服务器错误状态码） | 服务器处理请求出错 |

#### 1XX 信息

-   **100 Continue**  ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

#### 2XX 成功

-   **200 OK**  

-   **204 No Content**  ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。

-   **206 Partial Content**  ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

#### 3XX 重定向

-   **301 Moved Permanently**  ：永久性重定向

-   **302 Found**  ：临时性重定向

-   **303 See Other**  ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。

- 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。

-   **304 Not Modified**  ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。

-   **307 Temporary Redirect**  ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

#### 4XX 客户端错误

-   **400 Bad Request**  ：请求报文中存在语法错误。

-   **401 Unauthorized**  ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。

-   **403 Forbidden**  ：请求被拒绝。

-   **404 Not Found**  

#### 5XX 服务器错误

-   **500 Internal Server Error**  ：服务器正在执行请求时发生错误。

-   **503 Service Unavailable**  ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

### 四、HTTP 首部

有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。

各种首部字段及其含义如下（不需要全记，仅供查阅）：

#### 通用首部字段

| 首部字段名 | 说明 |
| :--: | :--: |
| Cache-Control | 控制缓存的行为 |
| Connection | 控制不再转发给代理的首部字段、管理持久连接|
| Date | 创建报文的日期时间 |
| Pragma | 报文指令 |
| Trailer | 报文末端的首部一览 |
| Transfer-Encoding | 指定报文主体的传输编码方式 |
| Upgrade | 升级为其他协议 |
| Via | 代理服务器的相关信息 |
| Warning | 错误通知 |

#### 请求首部字段

| 首部字段名 | 说明 |
| :--: | :--: |
| Accept | 用户代理可处理的媒体类型 |
| Accept-Charset | 优先的字符集 |
| Accept-Encoding | 优先的内容编码 |
| Accept-Language | 优先的语言（自然语言） |
| Authorization | Web 认证信息 |
| Expect | 期待服务器的特定行为 |
| From | 用户的电子邮箱地址 |
| Host | 请求资源所在服务器 |
| If-Match | 比较实体标记（ETag） |
| If-Modified-Since | 比较资源的更新时间 |
| If-None-Match | 比较实体标记（与 If-Match 相反） |
| If-Range | 资源未更新时发送实体 Byte 的范围请求 |
| If-Unmodified-Since | 比较资源的更新时间（与 If-Modified-Since 相反） |
| Max-Forwards | 最大传输逐跳数 |
| Proxy-Authorization | 代理服务器要求客户端的认证信息 |
| Range | 实体的字节范围请求 |
| Referer | 对请求中 URI 的原始获取方 |
| TE | 传输编码的优先级 |
| User-Agent | HTTP 客户端程序的信息 |

#### 响应首部字段

| 首部字段名 | 说明 |
| :--: | :--: |
| Accept-Ranges | 是否接受字节范围请求 |
| Age | 推算资源创建经过时间 |
| ETag | 资源的匹配信息 |
| Location | 令客户端重定向至指定 URI |
| Proxy-Authenticate | 代理服务器对客户端的认证信息 |
| Retry-After | 对再次发起请求的时机要求 |
| Server | HTTP 服务器的安装信息 |
| Vary | 代理服务器缓存的管理信息 |
| WWW-Authenticate | 服务器对客户端的认证信息 |

#### 实体首部字段

| 首部字段名 | 说明 |
| :--: | :--: |
| Allow | 资源可支持的 HTTP 方法 |
| Content-Encoding | 实体主体适用的编码方式 |
| Content-Language | 实体主体的自然语言 |
| Content-Length | 实体主体的大小 |
| Content-Location | 替代对应资源的 URI |
| Content-MD5 | 实体主体的报文摘要 |
| Content-Range | 实体主体的位置范围 |
| Content-Type | 实体主体的媒体类型 |
| Expires | 实体主体过期的日期时间 |
| Last-Modified | 资源的最后修改日期时间 |

### 五、具体应用

#### 连接管理

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP1_x_Connections.png" width="800"/> </div><br>

##### 1. 短连接与长连接

当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。

长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。

- 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 `Connection : close`；
- 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 `Connection : Keep-Alive`。

##### 2. 流水线

默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。

流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。

#### Cookie

HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。

Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。

Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。

##### 1. 用途

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

##### 2. 创建过程

服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。

```html
HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry

[page content]
```

客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。

```html
GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry
```

##### 3. 分类

- 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。
- 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。

```html
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
```

##### 4. 作用域

Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。

Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F ("/") 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：

- /docs
- /docs/Web/
- /docs/Web/HTTP

##### 5. JavaScript

浏览器通过 `document.cookie` 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。

```html
document.cookie = "yummy_cookie=choco";
document.cookie = "tasty_cookie=strawberry";
console.log(document.cookie);
```

##### 6. HttpOnly

标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 `document.cookie` API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。

```html
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
```

##### 7. Secure

标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。

##### 8. Session

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

使用 Session 维护用户登录状态的过程如下：

- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
- 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

##### 9. 浏览器禁用 Cookie

此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。

##### 10. Cookie 与 Session 选择

- Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
- Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

#### 缓存

##### 1. 优点

- 缓解服务器压力；
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

##### 2. 实现方法

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存。

##### 3. Cache-Control

HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。

**3.1 禁止进行缓存**  

no-store 指令规定不能对请求或响应的任何一部分进行缓存。

```html
Cache-Control: no-store
```

**3.2 强制确认缓存**  

no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。

```html
Cache-Control: no-cache
```

**3.3 私有缓存和公共缓存**  

private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。

```html
Cache-Control: private
```

public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。

```html
Cache-Control: public
```

**3.4 缓存过期机制**  

max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。

max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。

```html
Cache-Control: max-age=31536000
```

Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。

```html
Expires: Wed, 04 Jul 2012 08:26:05 GMT
```

- 在 HTTP/1.1 中，会优先处理 max-age 指令；
- 在 HTTP/1.0 中，max-age 指令会被忽略掉。

##### 4. 缓存验证

需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 `http://www.google.com/` 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。

```html
ETag: "82e22293907ce725faf67773957acd12"
```

可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。

```html
If-None-Match: "82e22293907ce725faf67773957acd12"
```

Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。

```html
Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT
```

```html
If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
```

#### 内容协商

通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。

##### 1. 类型

**1.1 服务端驱动型**  

客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language，服务器根据这些字段返回特定的资源。

它存在以下问题：

- 服务器很难知道客户端浏览器的全部信息；
- 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）；
- 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。

**1.2 代理驱动型**  

服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。

##### 2. Vary

```html
Vary: Accept-Language
```

在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。

例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 `Vary: Accept-Language` 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。

#### 内容编码

内容编码将实体主体进行压缩，从而减少传输的数据量。

常用的内容编码有：gzip、compress、deflate、identity。

浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，响应报文的 Vary 首部字段至少要包含 Content-Encoding。

#### 范围请求

如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。

##### 1. Range

在请求报文中添加 Range 首部字段指定请求的范围。

```html
GET /z4d4kWk.jpg HTTP/1.1
Host: i.imgur.com
Range: bytes=0-1023
```

请求成功的话服务器返回的响应包含 206 Partial Content 状态码。

```html
HTTP/1.1 206 Partial Content
Content-Range: bytes 0-1023/146515
Content-Length: 1024
...
(binary content)
```

##### 2. Accept-Ranges

响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。

```html
Accept-Ranges: bytes
```

##### 3. 响应状态码

- 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。
- 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。
- 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。

#### 分块传输编码

Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面。

#### 多部分对象集合

一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。

例如，上传多个表单时可以使用如下方式：

```html
Content-Type: multipart/form-data; boundary=AaB03x

--AaB03x
Content-Disposition: form-data; name="submit-name"

Larry
--AaB03x
Content-Disposition: form-data; name="files"; filename="file1.txt"
Content-Type: text/plain

... contents of file1.txt ...
--AaB03x--
```

#### 虚拟主机

HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。

#### 通信数据转发

##### 1. 代理

代理服务器接受客户端的请求，并且转发给其它服务器。

使用代理的主要目的是：

- 缓存
- 负载均衡
- 网络访问控制
- 访问日志记录

代理服务器分为正向代理和反向代理两种：

- 用户察觉得到正向代理的存在。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a314bb79-5b18-4e63-a976-3448bffa6f1b.png" width=""/> </div><br>

- 而反向代理一般位于内部网络中，用户察觉不到。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/2d09a847-b854-439c-9198-b29c65810944.png" width=""/> </div><br>

##### 2. 网关

与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。

##### 3. 隧道

使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。

### 六、HTTPS

HTTP 有以下安全性问题：

- 使用明文进行通信，内容可能会被窃听；
- 不验证通信方的身份，通信方的身份有可能遭遇伪装；
- 无法证明报文的完整性，报文有可能遭篡改。

HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。

通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ssl-offloading.jpg" width="700"/> </div><br>

#### 加密

##### 1. 对称密钥加密

对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。

- 优点：运算速度快；
- 缺点：无法安全地将密钥传输给通信方。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7fffa4b8-b36d-471f-ad0c-a88ee763bb76.png" width="600"/> </div><br>

##### 2.非对称密钥加密

非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。

公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。

非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。

- 优点：可以更安全地将公开密钥传输给通信发送方；
- 缺点：运算速度慢。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/39ccb299-ee99-4dd1-b8b4-2f9ec9495cb4.png" width="600"/> </div><br>

##### 3. HTTPS 采用的加密方式

上面提到对称密钥加密方式的传输效率更高，但是无法安全地将密钥 Secret Key 传输给通信方。而非对称密钥加密方式可以保证传输的安全性，因此我们可以利用非对称密钥加密方式将 Secret Key  传输给通信方。HTTPS 采用混合的加密机制，正是利用了上面提到的方案：

- 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性;
- 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key）

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/How-HTTPS-Works.png" width="600"/> </div><br>

#### 认证

通过使用   **证书**   来对通信方进行认证。

数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。

服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/2017-06-11-ca.png" width=""/> </div><br>

#### 完整性保护

SSL 提供报文摘要功能来进行完整性保护。

HTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。

HTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。

#### HTTPS 的缺点

- 因为需要进行加密解密等过程，因此速度会更慢；
- 需要支付证书授权的高额费用。

### 七、HTTP/2.0

#### HTTP/1.x 缺陷

HTTP/1.x 实现简单是以牺牲性能为代价的：

- 客户端需要使用多个连接才能实现并发和缩短延迟；
- 不会压缩请求和响应首部，从而导致不必要的网络流量；
- 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。

#### 二进制分帧层

HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/86e6a91d-a285-447a-9345-c5484b8d0c47.png" width="400"/> </div><br>

在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。

- 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。
- 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。
- 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/af198da1-2480-4043-b07f-a3b91a88b815.png" width="600"/> </div><br>

#### 服务端推送

HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e3f1657c-80fc-4dfa-9643-bf51abd201c6.png" width="800"/> </div><br>

#### 首部压缩

HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。

HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。

不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/_u4E0B_u8F7D.png" width="600"/> </div><br>

### 八、HTTP/1.1 新特性

详细内容请见上文

- 默认是长连接
- 支持流水线
- 支持同时打开多个 TCP 连接
- 支持虚拟主机
- 新增状态码 100
- 支持分块传输编码
- 新增缓存处理指令 max-age

### 九、GET 和 POST 比较

#### 作用

GET 用于获取资源，而 POST 用于传输实体主体。

#### 参数

GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。

因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 `中文` 会转换为 `%E4%B8%AD%E6%96%87`，而空格会转换为 `%20`。POST 参数支持标准字符集。

```
GET /test/demo_form.asp?name1=value1&name2=value2 HTTP/1.1
```

```
POST /test/demo_form.asp HTTP/1.1
Host: w3schools.com
name1=value1&name2=value2
```

#### 安全

安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。

GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。

安全的方法除了 GET 之外还有：HEAD、OPTIONS。

不安全的方法除了 POST 之外还有 PUT、DELETE。

#### 幂等性

幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。

所有的安全方法也都是幂等的。

在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。

GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的：

```
GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
GET /pageX HTTP/1.1
```

POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录：

```
POST /add_row HTTP/1.1   -> Adds a 1nd row
POST /add_row HTTP/1.1   -> Adds a 2nd row
POST /add_row HTTP/1.1   -> Adds a 3rd row
```

DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样：

```
DELETE /idX/delete HTTP/1.1   -> Returns 200 if idX exists
DELETE /idX/delete HTTP/1.1   -> Returns 404 as it just got deleted
DELETE /idX/delete HTTP/1.1   -> Returns 404
```

#### 可缓存

如果要对响应进行缓存，需要满足以下条件：

- 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。
- 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。
- 响应报文的 Cache-Control 首部字段没有指定不进行缓存。

#### XMLHttpRequest

为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：

> XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。

- 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。
- 而 GET 方法 Header 和 Data 会一起发送。
## socket


### 一、I/O 模型

一个输入操作通常包括两个阶段：

- 等待数据准备好
- 从内核向进程复制数据

对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。

Unix 有五种 I/O 模型：

- 阻塞式 I/O
- 非阻塞式 I/O
- I/O 复用（select 和 poll）
- 信号驱动式 I/O（SIGIO）
- 异步 I/O（AIO）

#### 阻塞式 I/O

应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。

应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。

下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。

```c
ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
```

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492928416812_4.png"/> </div><br>

## 非阻塞式 I/O

应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。

由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929000361_5.png"/> </div><br>

#### I/O 复用

使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。

它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。

如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929444818_6.png"/> </div><br>

#### 信号驱动 I/O

应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492929553651_7.png"/> </div><br>

#### 异步 I/O

应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492930243286_8.png"/> </div><br>

## 五大 I/O 模型比较

- 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
- 异步 I/O：第二阶段应用进程不会阻塞。

同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。

非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1492928105791_3.png"/> </div><br>

### 二、I/O 复用

select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。

#### select

```c
int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。

- fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。

- timeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。

- 成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。

```c
fd_set fd_in, fd_out;
struct timeval tv;

// Reset the sets
FD_ZERO( &fd_in );
FD_ZERO( &fd_out );

// Monitor sock1 for input events
FD_SET( sock1, &fd_in );

// Monitor sock2 for output events
FD_SET( sock2, &fd_out );

// Find out which socket has the largest numeric value as select requires it
int largest_sock = sock1 > sock2 ? sock1 : sock2;

// Wait up to 10 seconds
tv.tv_sec = 10;
tv.tv_usec = 0;

// Call the select
int ret = select( largest_sock + 1, &fd_in, &fd_out, NULL, &tv );

// Check if select actually succeed
if ( ret == -1 )
    // report error and abort
else if ( ret == 0 )
    // timeout; no event detected
else
{
    if ( FD_ISSET( sock1, &fd_in ) )
        // input event on sock1

    if ( FD_ISSET( sock2, &fd_out ) )
        // output event on sock2
}
```

#### poll

```c
int poll(struct pollfd *fds, unsigned int nfds, int timeout);
```

poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。

poll 中的描述符是 pollfd 类型的数组，pollfd 的定义如下：

```c
struct pollfd {
               int   fd;         /* file descriptor */
               short events;     /* requested events */
               short revents;    /* returned events */
           };
```


```c
// The structure for two events
struct pollfd fds[2];

// Monitor sock1 for input
fds[0].fd = sock1;
fds[0].events = POLLIN;

// Monitor sock2 for output
fds[1].fd = sock2;
fds[1].events = POLLOUT;

// Wait 10 seconds
int ret = poll( &fds, 2, 10000 );
// Check if poll actually succeed
if ( ret == -1 )
    // report error and abort
else if ( ret == 0 )
    // timeout; no event detected
else
{
    // If we detect the event, zero it out so we can reuse the structure
    if ( fds[0].revents & POLLIN )
        fds[0].revents = 0;
        // input event on sock1

    if ( fds[1].revents & POLLOUT )
        fds[1].revents = 0;
        // output event on sock2
}
```

#### 比较

##### 1. 功能

select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。

- select 会修改描述符，而 poll 不会；
- select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
- poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。

##### 2. 速度

select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。

##### 3. 可移植性

几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。

#### epoll

```c
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵**红黑树**上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。

从上面的描述可以看出，epoll 只需要将描述符从**进程缓冲区向内核缓冲区拷贝一次(通过一个链表结构)**，并且进程不需要通过轮询来获得事件完成的描述符。

epoll 仅适用于 Linux OS。

epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。

epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

```c
// Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets.
// The function argument is ignored (it was not before, but now it is), so put your favorite number here
int pollingfd = epoll_create( 0xCAFE );

if ( pollingfd < 0 )
 // report error

// Initialize the epoll structure in case more members are added in future
struct epoll_event ev = { 0 };

// Associate the connection class instance with the event. You can associate anything
// you want, epoll does not use this information. We store a connection class pointer, pConnection1
ev.data.ptr = pConnection1;

// Monitor for input, and do not automatically rearm the descriptor after the event
ev.events = EPOLLIN | EPOLLONESHOT;
// Add the descriptor into the monitoring list. We can do it even if another thread is
// waiting in epoll_wait - the descriptor will be properly added
if ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1->getSocket(), &ev ) != 0 )
    // report error

// Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen)
struct epoll_event pevents[ 20 ];

// Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event array
int ready = epoll_wait( pollingfd, pevents, 20, 10000 );
// Check if epoll actually succeed
if ( ret == -1 )
    // report error and abort
else if ( ret == 0 )
    // timeout; no event detected
else
{
    // Check if any events detected
    for ( int i = 0; i < ret; i++ )
    {
        if ( pevents[i].events & EPOLLIN )
        {
            // Get back our connection pointer
            Connection * c = (Connection*) pevents[i].data.ptr;
            c->handleReadEvent();
         }
    }
}
```


#### 工作模式

epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。

##### 1. LT 模式

当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。

##### 2. ET 模式

和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。

很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

#### 应用场景

很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。

##### 1. select 应用场景

select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。

select 可移植性更好，几乎被所有主流平台所支持。

##### 2. poll 应用场景

poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。

##### 3. epoll 应用场景

只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。

需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。

需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。

## rpc

# 计算机系统
## 进程
### 进程基本概念
进程的经典定义是一个执行中程序的实例，同时也是**资源分配的最小单元**。系统中的每个程序都运行在某个进程中的上下文中，上下文是由程序正确运行所需的状态组成的。这个状态包括存放在内存中的程序的**代码**和**数据**，它的**栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合**。
#### 状态
##### 三态模型：在多道程序系统中，进程在处理器上交替运行，状态也不断地发生变化。进程一般有3种基本状态：运行、就绪和阻塞。

1、 就绪：当一个进程获得了除处理机以外的一切所需资源，一旦得到处理机即可运行，则称此进程处于就绪状态。就绪进程可以按多个优先级来划分队列。例如，当一个进程由于时间片用完而进入就绪状态时，排入低优先级队列；当进程由I／O操作完成而进入就绪状态时，排入高优先级队列。

2、 运行：当一个进程在处理机上运行时，则称该进程处于运行状态。处于此状态的进程的数目小于等于处理器的数目，对于单处理机系统，处于运行状态的进程只有一个。在没有其他进程可以执行时（如所有进程都在阻塞状态），通常会自动执行系统的空闲进程。

3、 阻塞：也称为等待或睡眠状态，一个进程正在等待某一事件发生（例如请求I/O而等待I/O完成等）而暂时停止运行，这时即使把处理机分配给进程也无法运行，故称该进程处于阻塞状态。

##### 五态模型：对于一个实际的系统，进程的状态及其转换更为复杂。引入新建态和终止态构成了进程的五态模型。

1、 新建态： 对应于进程刚刚被创建时没有被提交的状态，并等待系统完成创建进程的所有必要信息。 进程正在创建过程中，还不能运行。操作系统在创建状态要进行的工作包括分配和建立进程控制块表项、建立资源表格（如打开文件表）并分配资源、加载程序并建立地址空间表等。创建进程时分为两个阶段，第一个阶段为一个新进程创建必要的管理信息，第二个阶段让该进程进入就绪状态。由于有了新建态，操作系统往往可以根据系统的性能和主存容量的限制推迟新建态进程的提交。

2、终止态：进程已结束运行，回收除进程控制块之外的其他资源，并让其他进程从进程控制块中收集有关信息（如记帐和将退出代码传递给父进程）。类似的，进程的终止也可分为两个阶段，第一个阶段等待操作系统进行善后处理，第二个阶段释放主存。
由于进程的不断创建，系统资源特别是主存资源已不能满足所有进程运行的要求。这时，就必须将某些进程挂起，放到磁盘对换区，暂时不参加调度，以平衡系统负载；进程挂起的原因可能是系统故障，或者是用户调试程序，也可能是需要检查问题。

3、活跃就绪：是指进程在主存并且可被调度的状态。

4、静止就绪（挂起就绪）：是指进程被对换到辅存时的就绪状态，是不能被直接调度的状态，只有当主存中没有活跃就绪态进程，或者是挂起就绪态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活跃就绪。

5.1、活跃阻塞：是指进程已在主存，一旦等待的事件产生便进入活跃就绪状态。

5.2、静止阻塞：是指进程对换到辅存时的阻塞状态，一旦等待的事件产生便进入静止就绪状态。
#### 进程控制块
进程控制块（PCB，Process Control Block），是操作系统核心中一种数据结构，主要表示进程状态。

虽各实际情况不尽相同，PCB通常记载进程之相关信息，包括：

- 进程状态：可以是new、ready、running、waiting或 blocked等。
- 程序计数器：接着要运行的指令地址。
- CPU寄存器：如累加器、变址寄存器、堆栈指针以及一般用途寄存器、状况代码等，主要用途在于中断时暂时存储数据，以便稍后继续利用；其数量及类别因电脑架构有所差异。
- CPU排班法：优先级、排班队列等指针以及其他参数。
- 内存管理：如页表等。
- 会计信息：如CPU与实际时间之使用数量、时限、账号、工作或进程号码。
- 输入输出状态：配置进程使用I/O设备，如磁带机。
总言之，PCB如其名，内容不脱离各进程相关信息。

### 进程间通信
进程间通信方式一般认为有六种，分别是管道、消息队列、共享内存、信号量、信号、socket
#### 管道
匿名管道和命名管道
- 管道pipe：管道是一种半双工的通信方式，数据只能**单向流动**，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。调用pipe函数，会在内核中开辟出一块**缓冲区**用来进行进程间通信，这块缓冲区称为管道，它有一个**读端**和一个**写端**。比如：
>> 父进程创建管道，得到两个文件描述符指向管道的两端
>> 利用fork函数创建出子进程，则子进程也得到两个文件描述符指向同一管道
>> 父进程关闭读端（pipe[0]）,子进程关闭写端pipe[1]，则此时父进程可以往管道中进行写操作，子进程可以从管道中读，从而实现了通过管道的进程间通信。(半双工的过程)
**pipe的特点**：
1. 只能单向通信
2. 只能血缘关系的进程进行通信
3. 依赖于文件系统
4. 生命周期随进程
5. 面向字节流的服务
6. 管道内部提供了同步机制

- 命名管道FIFO: FIFO可以在**无关的进程之间**交换数据，与无名管道不同。
FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
其中的 mode 参数与open函数中的 mode 相同。一旦创建了一个 FIFO，就可以用一般的文件I/O函数操作它。
当 open 一个FIFO时，是否设置非阻塞标志（O_NONBLOCK）的区别：
若没有指定O_NONBLOCK（默认），只读 open 要阻塞到某个其他进程为写而打开此 FIFO。类似的，只写 open 要阻塞到某个其他进程为读而打开它。
若指定了O_NONBLOCK，则只读 open 立即返回。而只写 open 将出错返回 -1 如果没有进程已经为读而打开该 FIFO，其errno置ENXIO。

#### 消息队列MessageQueue: 
- 消息队列是由消息的**链表**，**存放在内核中**并由**消息队列标识符**标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
1. 消息队列是**面向记录**的，其中的消息具有特定的格式以及特定的**优先级**。
2. 消息队列**独立于发送与接收进程**。进程终止时，消息队列及其内容并**不会被删除**。
3. 消息队列可以实现消息的**随机查询**,消息不一定要以先进先出的次序读取,也可以按消息的**类型读取**。

#### 共享内存SharedMemory: 
共享内存是系统出于多个进程之间通讯的考虑，而预留的的一块内存区。
- 当一个程序加载进内存后，它就被分成叫作页的块。

- 通信将存在内存的两个页之间或者两个独立的进程之间。

总之，当一个程序想和另外一个程序通信的时候，那内存将会为这两个程序生成一块公共的内存区域。这块被两个进程分享的内存区域叫做共享内存

因为所有进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。访问共享内存区域和访问进程独有的内存区域**一样快**，并不需要通过系统调用或者其它需要切入内核的过程来完成。同时它也避免了对数据的各种不必要的复制。

为了简化共享数据的完整性和避免同时存取数据，内核提供了一种专门存取共享内存资源的机制。这称为互斥体或者mutex对象

#### 信号量Semaphore: 
信号量本质上是一个**计数器**（不设置全局变量是因为进程间是相互独立的，而这不一定能看到，看到也不能保证++引用计数为原子操作）,用于多进程对共享数据对象的读取，它和管道有所不同，它不以传送数据为主要目的，它主要是用来**保护共享资源**（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。
**信号量在进行操作时是原子的。**

#### 信号 ( sinal ):
- 信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。

- 信号是进程间通信机制中唯一的**异步通信机制**，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。信号机制经过POSIX实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。

#### 套接字Socket:
基于数据报和流，具体过程在计算机网络中分析。
### 进程地址空间 
每个程序都能看到一片完整连续的地址空间，这些空间并没有直接关联到物理内存，而是操作系统提供了内存的一种抽象概念，使得每个进程都有一个连续完整的地址空间，在程序的运行过程，再完成虚拟地址到物理地址的转换。进程的地址空间是分段的，存在所谓的数据段，代码段，bbs段，堆，栈。
![]{../picg/linuxprocessaddressspace02.png}

- 从0xc000000000到0xFFFFFFFF共1G的大小是内核地址空间（后面再探讨内核地址空间，先重点关注用户地址空间），余下的低地址3G空间则是用户地址空间。
- Code VMA: 即程序的代码段，CPU执行的机器指令部分。通常，这一段是可以共享的，即多线程共享进程的代码段。并且，此段是只读的，不能修改。
- Data VMA: 即程序的数据段，包含ELF文件在中的data段和bss段。
- 堆和栈: 这两个大家都十分熟悉了，new或者malloc分配的空间在堆上，需要程序猿维护，若没有主动释放堆上的空间，进程运行结束后会被释放。栈上的是函数栈临时的变量，还有程序的局部变量，自动释放。
- 共享库和**mmap内容映射区**：位于栈和堆之间，例如程序使用的printf，函数共享库printf.o固定在某个物理内存位置上，让许多进程映射共享。mmap是一个系统函数，可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址。此处参考后面的第三条。
- 命令行参数: 程序的命令行参数
- 环境变量：类似于Linux下的PATH，HOME等环境变量，子进程会继承父进程的环境变量。
## 进程调度算法
这里主要区分两种系统：批处理系统和交互式处理系统。这里时间片轮转是交互式处理系统。
### 先来先服务调度算法（First Come First Served, FCFS）
是最简单的调度算法，可以用于作业调度和进程调度。按照作业进入系统后备作业队列的先后次序来挑选作业，加入就绪队列，等待执行。
### 短作业优先
短作业优先调度算法（Short Job First）用于进程调度时又被称为短进程优先调度算法（Short Process First），该算法既可以用于作业调度，又可以用于进程调度。

在作业调度中，该算法每次从后备作业队列中挑选估计服务时间最短的一个或几个作业，将他们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中的原理类似。
### 最短剩余时间优先
SJF本身是非抢占式的，用于抢占式调度系统时，对应的算法陈伟最短剩余时间优先调度算法。

该算法首先按照作业的服务时间挑选最短的作业运行，在该作业运行期间，一旦有新作业到达系统，并且该新作业的服务时间比当前运行作业的剩余服务时间短，则发生抢占；否则，当前作业继续运行。该算法确保一旦新的短作业或短进程进入系统，能够很快得到处理。
### 高响应比优先
高响应比优先调度算法（Highest Reponse Ratio First, HRRF）是非抢占式的，主要用于作业调度。

基本思想：每次进行作业调度时，先计算后备作业队列中每个作业的响应比，挑选最高的作业投入系统运行。

响应比 = （等待时间 + 服务时间） / 服务时间 = 等待时间 / 服务时间 + 1
### 时间片轮转
用于分时系统的进程调度。

基本思想：系统将CPU处理时间划分为若干个时间片（q），进程按照到达先后顺序排列。每次调度选择队首的进程，执行完1个时间片q后，计时器发出时钟中断请求，该进程移至队尾。以后每次调度都是如此。该算法能在给定的时间内响应所有用户的而请求，达到分时系统的目的。

其性能主要取决于时间片q的大小，q太大，则所有的进程在1个时间片完成，退外围FCFS；太小则进程频繁切换，系统开销大。

该算法简单有效，常用于分时系统，但不利于I/O频繁的而紧凑，由于这种进程用不完一个时间片，就因为等待I/O操作而被阻塞，当I/O操作结束后，只能插入到就绪队列的末尾，等待下一轮调度。
### fork()函数
- fork：	fork创造的子进程是父进程的完整副本，复制了父亲进程的资源，包括内存的内容task_struct内容
- vfork：	vfork创建的子进程与父进程共享数据段,而且由vfork()创建的子进程将先于父进程运行
- clone：	Linux上创建线程一般使用的是pthread库 实际上linux也给我们提供了创建线程的系统调用，就是clone

**task_struct:**
```
Linux内核通过一个被称为进程描述符的task_struct结构体来管理进程，这个结构体包含了一个进程所需的所有信息。它定义在include/linux/sched.h文件中。
5个互斥状态
2个终止状态
新增睡眠状态

```
vfork()用法与fork()相似.但是也有区别,具体区别归结为以下3点

fork() 子进程拷贝父进程的数据段，代码段.
vfork() 子进程与父进程共享数据段.|

fork() 父子进程的执行次序不确定.
vfork():保证子进程先运行，

vfork()保证子进程先运行，在她调用exec或_exit之后父进程才可能被调度运行。如果在
调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

在调用exec或_exit之前与父进程数据是共享的,在它调用exec或_exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。当需要改变共享数据段中变量的值，则拷贝父进程

vfork用于创建一个新进程，而该新进程的目的是exec一个新进程，vfork和fork一样都创建一个子进程，但是它并不将父进程的地址空间完全复制到子进程中，不会复制页表。因为子进程会立即调用exec，于是也就不会存放该地址空间。不过在子进程中调用exec或exit之前，他在父进程的空间中运行。

如果在调用vfork时子进程依赖于父进程的进一步动作，则会导致死锁。由此可见，这个系统调用是用来启动一个新的应用程序。其次，子进程在vfork()返回后直接运行在父进程的栈空间，并使用父进程的内存和数据。这意味着子进程可能破坏父进程的数据结构或栈，造成失败。

为了避免这些问题，需要确保一旦调用vfork()，子进程就不从当前的栈框架中返回，并且如果子进程改变了父进程的数据结构就不能调用exit函数。

子进程还必须避免改变全局数据结构或全局变量中的任何信息，因为这些改变都有可能使父进程不能继续。通常，如果应用程序不是在fork()之后立即调用exec()，就有必要在fork()被替换成vfork()之前做仔细的检查。


## 线程
### 线程基本概念
 是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。
### 多线程通信
线程间的通信目的主要是用于**线程同步**，所以线程没有像进程通信中的用于数据交换的通信机制。
- 锁机制：包括互斥锁、条件变量、读写锁
互斥锁提供了以排他方式防止数据结构被并发修改的方法。
读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量

- 信号机制(Signal)：类似进程间的信号处理
### 线程与进程的区别
进程和线程的主要差别在于它们是不同的操作**系统资源管理方式**。进程有**独立的地址空间**，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的**堆栈和局部变量**，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程

1、拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问同一进程的资源
2、调度
线程是独立调度的基本单位，同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程内的线程会引起进程切换

3、系统开销
创建和撤销进程时，系统都要为之分配或回收资源，所付出的开销远大于创建或撤销线程时的开销。同样的在进程切换时，也会涉及当前执行进程 CPU 环境的保存以及新调度进程 CPU 环境的设置，而线程的切换只需保存和设置少量寄存器的内容，开销很小

4、通信方面
进程间通信需要进程同步和互斥手段的辅助，以保证数据的一致性。而线程间可以通过直接读/写同意进程中的数据段（如全局变量）来进行通信。
### 线程池
队列：
```
// SafeQueue.h

#pragma once 
#include <mutex> 
#include <queue> 
// Thread safe implementation of a Queue using a std::queue

template <typename T>
class SafeQueue {
private:
  std::queue<T> m_queue; //利用模板函数构造队列

  std::mutex m_mutex;//访问互斥信号量

public:
  SafeQueue() { //空构造函数


  }

  SafeQueue(SafeQueue& other) {//拷贝构造函数

    //TODO:
  }

  ~SafeQueue() { //析构函数

  }


  bool empty() {  //队列是否为空

    std::unique_lock<std::mutex> lock(m_mutex); //互斥信号变量加锁，防止m_queue被改变

    return m_queue.empty();
  }
  
  int size() {
    std::unique_lock<std::mutex> lock(m_mutex); //互斥信号变量加锁，防止m_queue被改变

    return m_queue.size();
  }
//队列添加元素

  void enqueue(T& t) {
    std::unique_lock<std::mutex> lock(m_mutex);
    m_queue.push(t);
  }
//队列取出元素

  bool dequeue(T& t) {
    std::unique_lock<std::mutex> lock(m_mutex); //队列加锁

    if (m_queue.empty()) {
      return false;
    }
    t = std::move(m_queue.front()); //取出队首元素，返回队首元素值，并进行右值引用
    
    m_queue.pop(); //弹出入队的第一个元素

    return true;
  }
};
```
线程池：
```
//ThreadPool.h

#pragma once 
#include <functional> 
#include <future> 
#include <mutex> 
#include <queue> 
#include <thread> 
#include <utility> 
#include <vector> 
#include "SafeQueue.h" 
class ThreadPool {
private:
  class ThreadWorker {//内置线程工作类

  private:
    int m_id; //工作id

    ThreadPool * m_pool;//所属线程池

  public:
    //构造函数

    ThreadWorker(ThreadPool * pool, const int id) 
      : m_pool(pool), m_id(id) {
    }
    //重载`()`操作

    void operator()() {
      std::function<void()> func; //定义基础函数类func
      
      bool dequeued; //是否正在取出队列中元素
      
      //判断线程池是否关闭，没有关闭，循环提取

      while (!m_pool->m_shutdown) {
        {
          //为线程环境锁加锁，互访问工作线程的休眠和唤醒

          std::unique_lock<std::mutex> lock(m_pool->m_conditional_mutex);
          //如果任务队列为空，阻塞当前线程

          if (m_pool->m_queue.empty()) {
            m_pool->m_conditional_lock.wait(lock); //等待条件变量通知，开启线程

          }
          //取出任务队列中的元素

          dequeued = m_pool->m_queue.dequeue(func);
        }
        //如果成功取出，执行工作函数

        if (dequeued) {
          func();
        }
      }
    }
  };

  bool m_shutdown; //线程池是否关闭

  SafeQueue<std::function<void()>> m_queue;//执行函数安全队列，即任务队列

  std::vector<std::thread> m_threads; //工作线程队列

  std::mutex m_conditional_mutex;//线程休眠锁互斥变量

  std::condition_variable m_conditional_lock; //线程环境锁，让线程可以处于休眠或者唤醒状态

public:
    //线程池构造函数

  ThreadPool(const int n_threads)
    : m_threads(std::vector<std::thread>(n_threads)), m_shutdown(false) {
  }

  ThreadPool(const ThreadPool &) = delete; //拷贝构造函数，并且取消默认父类构造函数

  ThreadPool(ThreadPool &&) = delete; // 拷贝构造函数，允许右值引用

  ThreadPool & operator=(const ThreadPool &) = delete; // 赋值操作

  ThreadPool & operator=(ThreadPool &&) = delete; //赋值操作

  // Inits thread pool

  void init() {
    for (int i = 0; i < m_threads.size(); ++i) {
      m_threads[i] = std::thread(ThreadWorker(this, i));//分配工作线程

    }
  }

  // Waits until threads finish their current task and shutdowns the pool

  void shutdown() {
    m_shutdown = true;
    m_conditional_lock.notify_all(); //通知 唤醒所有工作线程
    
    for (int i = 0; i < m_threads.size(); ++i) {
      if(m_threads[i].joinable()) { //判断线程是否正在等待

        m_threads[i].join();  //将线程加入等待队列

      }
    }
  }

  // Submit a function to be executed asynchronously by the pool
  //线程的主要工作函数，使用了后置返回类型，自动判断函数返回值

  template<typename F, typename...Args>
  auto submit(F&& f, Args&&... args) -> std::future<decltype(f(args...))> {
    // Create a function with bounded parameters ready to execute
    // 

    std::function<decltype(f(args...))()> func = std::bind(std::forward<F>(f), std::forward<Args>(args)...);//连接函数和参数定义，特殊函数类型,避免左、右值错误

    // Encapsulate it into a shared ptr in order to be able to copy construct // assign 
    //封装获取任务对象，方便另外一个线程查看结果

    auto task_ptr = std::make_shared<std::packaged_task<decltype(f(args...))()>>(func);

    // Wrap packaged task into void function
    //利用正则表达式，返回一个函数对象

    std::function<void()> wrapper_func = [task_ptr]() {
      (*task_ptr)(); 
    };

    // 队列通用安全封包函数，并压入安全队列

    m_queue.enqueue(wrapper_func);

    // 唤醒一个等待中的线程

    m_conditional_lock.notify_one();

    // 返回先前注册的任务指针

    return task_ptr->get_future();
  }
};
```
## 中断
中断指处理机处理程序运行中出现的紧急事件的整个过程.程序运行过程中，系统外部、系统内部或者现行程序本身若出现紧急事件，处理机立即中止现行程序的运行，自动转入相应的处理程序(中断服务程序)，待处理完后，再返回原来的程序运行，这整个过程称为程序中断。

 CPU要做的事情：
 改变工作模式至中断模式
```
保存现场

分析中断原因，跳到中断起始地址处理中断

返回到原来模式

恢复现场继续执行原来的程序。
```
---
layout: post
title: linux下的中断机制
categories: [linux]
description: linux interrupt 中断
keywords: linux interrupt 中断
---
文章来源：https://github.com/lrita/lrita.github.io
### 中断的定义与种类

Linux中的中断异常机制[^1]：

> 中断（interrupt）被定义为一个事件，该事件改变处理器执行的指令顺序，这样的事件与CPU芯片内外部硬件电路产生的电信号相对应。**中断通常分为同步（synchronous）中断和异步（asynchronous）中断**。
>
> * 同步中断指的是当指令执行时由CPU控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后CPU才会发出中断。
> * 异步中断是由其他硬件设备依照CPU时钟信号随机产生的。
>
> 在Intel处理器中，**把同步中断和异步中断分别称为异常（exception）和中断（interrupt）**。我们这里也采用这种分类。我们也使用中断信号来统称中断和异常。
>
> 中断是由间隔定时器和I/O设备产生的，例如，用户的一次按键会引起一个中断，虽然用户没有感觉，但是按键这个过程到下一次按键之间的间隔对于计算机指令时间来说是非常长的。
>
> 另一方面，异常是由程序的错误产生的，或者由内核必须处理的异常条件产生的。第一种情况下，内核通过发送一个每个Unix程序员都熟悉的信号来处理异常，第二种情况下，内核执行恢复异常需要的所有步骤，例如缺页异常。
>
> 中断信号提供了一种特殊的方式，使处理器转而去运行正常的控制流之外的代码。当一个中断信号到达时，CPU必须停止它当前正在做的事情，保留上下文，并切换产生中断后的一个空间。
>
> 虽然进程切换和中断都会导致内核保存上下文并且切换到另一空间，但中断处理程序和进程切换有一个明显的差异，由中断或异常处理程序执行的代码不是一个进程，更确切的说，它是一个内核执行路径，代表中断发生时正在运行的进程执行。作为一个内核控制路径，中断处理程序要比一个进程更轻量。
>
> 中断处理是由内核执行的最敏感的任务之一，因此它必须满足下面的约束：
>
> 当内核正打算去完成一些别的事情时，中断会随时到来。因此，内核的目标就是让中断尽可能快的处理完，尽其所能把更多的处理向后推迟。例如一个数据块已经到达了网线，当硬件中断内核时，内核只简单的标志数据到来了，让处理器恢复到它以前的运行状态，其余的处理稍后再进行。因此，内核响应中断后需要进行的操作氛围两部分，关键而紧急的部分内核立即执行，其他的推迟的部分内核随后会执行。
>
> 因为中断随时到来，所以内核可能正在处理其中一个中断的时候，另一个中断又会到来，应该尽可能多的允许这样的情况发生，因为这能维持更多的I/O设备处于忙状态，提高I/O设备的吞吐量。因此中断处理程序必须便写成使相应的内核控制路径能以嵌套的方式执行。当最后一个内核控制路径终止时，内核必须能恢复被中断执行的进程。
>
> 尽管内核在处理前一个中断时可以接受一个新的中断，但在内核代码中还是存在一些临界区，在临界区中，中断必须被禁止。必须尽可能的限制这样的临界区，因为根据以前的要求，内核，尤其时中断处理程序，应该在大部分时间内以开中断的方式运行。
>
> Intel文档把中断和异常分为以下几类：
>
> 中断：
>
> * 可屏蔽中断，I/O设备发出的所有中断请求（IRQ）都产生可屏蔽中断，一个屏蔽的中断只要还是屏蔽的，控制单元就可以忽略它。
> * 非屏蔽中断，有一些危险的事件才能引起非屏蔽中断，例如硬件故障，非屏蔽中断总是由CPU辨认。
>
> 异常：
>
> 当CPU执行指令时探测到一个异常，会产生一个处理器探测异常（processor-detected exception），可以进一步区分，这取决于CPU控制单元产生异常时保存在内核堆栈eip寄存器的值。
>
> * 故障（fault），通常可以纠正，一旦纠正，程序就可以重新开始，保存在eip寄存器中的值是引起故障的指令地址。
> * 陷阱（trap）在陷阱指令执行后立即报告，内核把控制权烦给程序后就可以继续它的执行而不失连续性。保存在eip中的值是一个随后要执行的指令地址。陷阱的主要作用是为了调试程序。
> * 异常中止（abort），发生一个严重的错误，控制单元出了问题，不能在eip寄存器中保存引起异常的指令所在的确切位置。异常中止用于报告严重的错误，例如硬件故障或系统表中无效的值或者不一致的值。这种异常会强制中止进程。
> * 编程异常（programmed exception），在编程者发出的请求时发送，是由int或int3指令触发的。
>
> 每个中断和异常是由0～255之间的一个数来标识的，Intel把这个8位无符号整数叫做一个向量（vector）。非屏蔽中断的向量和异常的向量是固定的，而可屏蔽中断的向量是可以通过对中断控制器的编程来改变。

在X86中，分为实模式和保护模式，实模式通常是CPU启动到BIOS再到操作系统启动前的这段时间，操作启动初始化完成进入到保护模式。在不同模式下中断的处理机制同步，在这里只**简单探讨一下保护模式下的中断机制**。

### 中断的初始化

Intel X86位处理器有256个硬中断号，用一个8位的无符号整数表示，被叫做一个向量（vector）。

> 中断描述符表（Interrupt Descriptor Table，`IDT`）是一个系统表，它与每一个中断或异常向量相联系，每一个向量在表中有相应地中断或异常处理程序地入口地址，内核在允许中断发生前，必须适当地初始化IDT。

在`IDT`中可以存储以下三种`Gate Descriptor`（门描述符）：用于描述和控制`Interrupt Service Routine`（每个中断对应的回调函数）的访问，它们分别是：
* Interrupt Gate Descriptor（中断门描述符），包含段选择符和中断或异常处理程序地段内偏移量，当控制权转移到一个适当地段时，处理器清IF标志，从而关闭将来会发生的可屏蔽中断。
* Trap Gate Descriptor（陷井门描述符），和中断门类似，只是控制权传递到一个适当地段处理器不修改IF标志。
* Task Gate Descriptor（任务门描述符），Linux中未使用该类型，当中断信号发生时，必须取代当前进程地那个进程地TSS选择符存放在任务门中。

> `IDT`表中地每一项`Gate Descriptor`由8个字节组成，因此，最多需要256x8=2048字节来存放IDT（64位时扩展到16个字节）。因为需要增加权限控制等因素，在`IDT`中并不直接关联到`Interrupt Service Routine`。

`IDTR`是一个CPU寄存器，用以存储`IDT`的基地址与段大小，用以快速访问。机器指令`LLDT`和`SLDT`是分别用来设置和保存`LDTR`寄存器的值[^2]。

![](/images/posts/linux/062111_1451_x86x8664CPU11_IDTR.png)

在内核初始化的时候，会为每一个中断向量注册一个对应的回调函数（`Interrupt Service Routine`），初始化`IDT`与`IDTR`寄存器：
```c
// init/main.c
asmlinkage void __init start_kernel(void)
{
    ...
    setup_arch(&command_line); // 初始化架构相关的，其中包含一些与架构相关的中断，
                               // Page Fault相关的中断就在其内部注册
    ...
    trap_init();    // 初始化异常处理
    ...
    init_IRQ();     // 初始化外部中断
    ...
    init_timers();  // 初始化定时器模块，同时，会注册定时器的软中断处理函数
    ...
    softirq_init(); // 初始化软中断
}

// 在setup_arch中会调用early_trap_pf_init/early_trap_init，其中会注册
// Page Fault异常对应的中断函数page_fault
/* Set of traps needed for early debugging. */
void __init early_trap_init(void)
{
    set_intr_gate_ist(X86_TRAP_DB, &debug, DEBUG_STACK);
    /* int3 can be called from all */
    set_system_intr_gate_ist(X86_TRAP_BP, &int3, DEBUG_STACK);
#ifdef CONFIG_X86_32
    set_intr_gate(X86_TRAP_PF, &page_fault);
#endif
    load_idt(&idt_descr);
}

void __init early_trap_pf_init(void)
{
#ifdef CONFIG_X86_64
    set_intr_gate(X86_TRAP_PF, &page_fault);
#endif
}
```

更加详细的流程可以参考下面几张图，出自[^3]。

![](/images/posts/linux/interrupt-0.png)

![](/images/posts/linux/interrupt-1.jpg)

![](/images/posts/linux/interrupt-2.jpg)

![](/images/posts/linux/interrupt-3.jpg)

在初始化完成后，每个中断向量都会有一个对应的回调函数（`Interrupt Service Routine`），不同的中断向量对应不同的软件逻辑，如果系统不关心，则置为`ignore_int`：

| 中断向量号 | 异常事件 | Linux的函数 |
| -------- | ------ | ---------- |
| 0 | 除法错误 | divide_error |
| 1 | 调试异常 | debug |
| 2 | NMI中断 | nmi |
| 3	| 单字节，int 3 | int3 |
| 4 | 溢出 | overflow |
| 5 | 边界监测中断 | bounds |
| 6 | 无效操作码 | invalid_op |
| 7 | 设备不可用 | device_not_available |
| 8 | 双重故障 | double_fault |
| 9 | 协处理器段溢出 | coprocessor_segment_overrun |
| 10 | 无效TSS | invalid_TSS |
| 11 | 缺段中断 | segment_not_present |
| 12 | 堆栈异常 | stack_segment |
| 13 | 一般保护异常 | general_protection |
| 14 | 页异常 | page_fault |
| 15 | | spurious_interrupt_bug |
| 16 | 协处理器出错 | coprocessor_error |
| 17 | 对齐检查中断 | alignment_check |
| 0x80 | 系统调用 | ia32_syscall |
| 0xf9 | 内核调试 | call_debug |

上面表格中的这些对应函数，都只是由汇编实现的跳转函数，他们的实现在`arch/x86/kernel/entry_64.S`，基本上都是处理一下必要的上下文，然后跳转到相关的C实现的函数`do_xxx`中[^4]。

| 中断向量号 | 异常事件 | Linux汇编 | 调用c函数 | 处理结果 |
| 0 | 除法错误 | divide_error | do_divide_error | 发送SIGFPE信号 |
| 1	| 调试异常 | debug | do_debug | 发送SIGTRAP信号 |
| 2 | NMI中断 | nmi | do_nmi | |
| 3 | 单字节，int 3 | int3 | do_int3 | 发送SIGTRAP信号 |
| 4 | 溢出 | overflow | do_overflow | 发送SIGSEGV信号 |
| 5 | 边界监测中断 | bounds | do_bounds | 发送SIGSEGV信号 |
| 6	| 无效操作码 | invalid_op | do_invalid_op | 发送SIGILL信号 |
| 7 | 设备不可用 | device_not_available | do_device_not_available | 发送SIGSEGV信号 |
| 8	| 双重故障 | double_fault | do_double_fault |
| 9	| 协处理器段溢出 | coprocessor_segment_overrun | do_coprocessor_segment_overrun | 发送SIGFPE信号 |
| 10 | 无效TSS | invalid_TSS | do_invalid_TSS | 发送SIGSEGV信号 |
| 11 | 缺段中断 | segment_not_present | do_segment_not_present | 发送SIGBUS信号 |
| 12 | 堆栈异常 | stack_segment | do_stack_segment |
| 13 | 一般保护异常 | general_protection | do_general_protection |
| 14 | 页异常 | page_fault | do_page_fault | 处理缺页中断 |
| 15 | | spurious_interrupt_bug | do_spurious_interrupt_bug |
| 16 | 协处理器出错 | coprocessor_error | do_coprocessor_error | 发送SIGFPE信号 |
| 17 | 对齐检查中断 | alignment_check | do_alignment_check | 发送SIGBUS信号 |
| 0x80 | 系统调用 | ia32_syscall |
| 0xf9 | 内核调试 | call_debug | do_call_debug |

### 中断和异常的硬件处理[^5]

#### 中断触发

> 假定内核已经被初始化，因此，CPU在保护模式下运行，Linux只有在刚刚启动的时候是在实模式，之后便进入保护模式。
>
> 在执行了一条指令之后，cs和eip这对寄存器包含下一条将要执行的指令的逻辑地址，在处理了那条指令之后，控制单元会检查在运行前一条指令时是否已经发生了一个中断异或异常。如果发生了一个中断或者异常，那么控制单元执行下列操作：
>
> 1. 确定与中断或异常的关联向量i。
> 2. 读由`IDTR`寄存器指向的`IDT`表中的第i项门描述符。
> 3. 从`GDTR`寄存器获得`GDT`的基地址，并在`GDT`中查找，以读取`IDT`表项中的选择符所标识的段描述符，这个描述符指定中断或异常处理程序所在的段的基地址。
> 4. 确定中断是由授权的中断发生源发出的。(Why？因为INT指令允许用户态的进程产生中断信号，其向量值可以为0到255的任一值，为了避免用户通过INT指令产生非法中断，在初始化的时候，将向量值为80H的门描述符（系统调用使用该门）的DPL设为3，将其他需要避免访问的门描述符的DPL值设为0，这样在做权限检查的时候就可以检查出来非法的情况。)
> 5. 检查是否发生了特权等级变化。如果是由用户态陷入了内核态，控制单元必须开始使用与新的特权级相关的堆栈
>   5.1. 读`TR`寄存器，访问运行进程的`TSS`段。（why？因为任何进程从用户态陷入内核态都必须从`TSS`获得内核堆栈指针。)
>   5.2. 用与新特权级相关的栈段和栈指针装载ss和esp寄存器。这些值可以在进程的`TSS`段中找到。
>   5.3. 在新的栈（内核栈）中保存用户态的ss和esp，这些值指明了用户态相关栈的逻辑地址。
> 6. 如果故障已经发生，用引起异常的指令地址装载cs和eip寄存器，从而使这条指令能够再次被执行。
> 7. 在栈中保存eflags、cs以及eip的内容。
> 8. 如果异常产生了一个硬件出错码，则保存在栈中。
> 9. 装载cs和eip寄存器，其值分别是`IDT`表中的第i项门描述符的段选择符和偏移量，这些值给出了中断或者异常处理程序的第一条指令的逻辑地址（开始执行中断回调函数）。

#### 中断返回

> 中断或异常被处理完毕后，相应的处理程序必须产生一条`iret`指令，把控制权转交给被中断的进程，这样控制单元就会产生以下操作：
>
> 1. 用保存在栈中的值装载cs、eip或eflags寄存器，如果一个硬件出错码曾被押入栈中，并且在eip内容上面，那么执行iret指令必须先弹出这个硬件出错码。
> 2. 检查处理程序的CPL是否等于cs中的最低两位的值，如果是，说明在同一特权级，iret中止执行，否则转入下一步。
> 3. 从栈中装载ss和esp寄存器，返回到与旧特权级相关的栈。
> 4. 检查ds、es、fs以及gs段寄存器的内容，如果其中一个寄存器包含的选择符是个段描述符，并且其DPL值小于CPL，那么就清除相应的段寄存器。
### 软中断
软中断，顾名思义，是由软件产生的中断。不同于硬件中断由硬件发出中断、打断处理器，软中断一般来说是由某个过程发起的，随后打断目的进程的执行，使其执行注册的软中断处理程序。

为什么要有软中断这种东西呢？这涉及到Linux对中断处理过程的实现。Linux将中断处理分成了两个部分：上半部(top-half)和下半部(bottom-half)。上半部完成与硬件紧密相关的工作，一般来说需要关闭中断执行（关闭所在中断线或本地中断）；下半部完成可以在稍后执行的、不那么迫切的工作。由于下半部可以推后执行，因此可以让这部分代码委托给一个进程执行。为了能够告知该进程下半部的执行时机，就需要一种机制，能够中断这个进程，使它执行相应的处理函数。这就是软中断机制的目的。

实际上，下半部更常用的是tasklet，但是它也是由软中断实现的，因此研究软中断机制也是非常有用的。软中断的代码位于 kernel/softirq.c 文件中。
#### 软中断实现
软中断是在编译期静态分配的，它不像tasklet那样可以被动态注册或注销。软中断由一个特有的结构softirq_action表示，它定义在<linux/interrupt.h>中：
```cpp
struct softirq_action
{
    void    (*action)(struct softirq_action *);
};
```
软中断的可用数量是在编译时期固定的，在 kernel/softiqr.c 中定义了一个与之相关的数组：
```
static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
```
其中，NR_SOFTIRQS 是已经使用的软中断的数量，也定义在该文件中：
**一个软中断不会抢占另一个软中断。实际上，唯一可以抢占软中断的是中断处理程序。不过，其他的软中断（甚至是相同类型的软中断）可以在其他处理器上同时执行。**
一个注册的软中断必须在被标记后才会执行。这被称为触发软中断(raising the softirq)。通常，中断处理程序会在返回前标记它的软中断，使其在稍后执行。于是，在合适的时刻，该软中断就会运行。该触发接口为：

> void raise_softirq(unsigned int nr);
其中nr是软中断处理程序在数组中的对应下标。
#### 软中断的处理时机
待处理的软中断在下面这些地方会被检查和执行：

从一个硬件中断代码返回时；
在ksoftirq内核线程中；
在那些显式检查和执行待处理的软中断的代码中，如网络子系统中。
不管用什么方法唤起，软中断都是在do_softirq()中得到执行的。
**软中断保留给系统中对时间要求最严格以及最重要的下半部使用。如果你想加入一个新的软中断，首先应该问问自己为什么用tasklet实现不了。tasklet可以动态生成，由于它们对加锁的要求不高，所以使用起来也很方便，同时它们的性能也很不错。当然，对于时间要求严格并且能自己高效地完成加锁工作的应用，软中断会是正确的选择。**

## 系统调用
https://blog.csdn.net/gatieme/article/details/50779184
## 内存管理
https://qiankunli.github.io/2019/05/31/linux_memory.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86
## 工作队列
https://www.cnblogs.com/ck1020/p/8312652.html
## 页和段高速缓存
https://blog.51cto.com/12118369/1964957
## 计算机操作系统相关面试题
https://zhuanlan.zhihu.com/p/23755202
# 数据库
## mysql
## redis

# 高并发与分布式
