# 数据库
## mysql
https://juejin.im/post/5d1758d06fb9a07eed351405
文章 cnblogs.com/canchi/p/12040744.html

MySQL面试总结

### MySQL的存储引擎

`MyISAM`（默认表类型）：非事务的存储引擎，基于传统的`ISAM`（有索引的顺序访问方法）类型，是存储记录和文件的标准方法，不是事务安全，不支持外键，适用于频繁的查询。表锁，不会出现死锁，适合小数据和小并发。

- 为什么不会出死锁？（没有事务就不会继续持有锁）

答：因为`MyISAM`再查询的时候，会同时锁定这个`sql`里面所有用到的表（获取锁的顺序是一致的），不局限与一张表，再写锁又重叠时，就得等待。

**注意：【`MySQL5.5`之前默认的是`MyISAM`引擎了，5.5之后的版本默认都是`innodb`作为存储引擎】**

`innodb`：支持事务安全的存储引擎，适用于插入和更新，支持外键，行锁，事务。适合大数据，大并发。特别是针对多个并发和`QPS`较高的情况。

- `QPS：`就是每秒查询率，`QPS`是对一个特定服务器再规定时间内能处理多少流量的衡量标准。

- `TPS：`就是每秒传输处理的事务个数。

- `innodb`的行锁模式：共享锁，排他锁，意向共享锁（表锁），意向排他锁（表锁），间隙锁。（注意：如果`sql`语句没有使用索引，`innodb`不能确定操作的行时，使用意向锁（表锁））。

- 死锁问题

- 什么是死锁？

死锁就是当俩个事务都需要获取对方持有的排他锁才能完成事务的时候，就导致了循环锁等待，常见的死锁类型。

- 解决办法

1. 数据库参数
2. 尽量约定程序读取表的顺序
3. 在处理一个表时，尽量对处理的顺序排序
4. 调整事务隔离级别（避免俩个事务同时操作一行不存在的数据，容易发生死锁）

存储引擎还有：

- `MERGE：`将多个类似的`MyISAM`表分组为一个表，可以处理非事务性表，默认情况下包括这些表。
- `MEMORY：`提供内存中的表，以前称为堆。它在RAM中处理所有数据，以便比在磁盘上存储数据更快地访问。用于快速查找引用和其他相同的数据。
- `EXAMPLE：`可以使用此引擎创建表，但不能存储或获取数据。这样做的目的是教开发人员如何编写新的存储引擎。
- `ARCHIVE：`用于存储大量数据，不支持索引。
- `CSV：`在文本文件中以逗号分隔值格式存储数据。
- `BLACKHOLE：`受要存储的数据，但始终返回空。
- `FEDERATED：`将数据存储在远程数据库中。

### 数据表的类型


`MyISAM`，`InnoDB`，`MEMORY`，`HEAP`，`BOB`，`ARCHIVE`，`CSV`等

- `MYISAM：`成熟稳定，易于管理，快速读取。表级锁。
- `Innodb：`数据行锁。占用空间大，不支持全文索引。

### `MySQL`作为发布系统的储存，一天五万条以上的增量，怎么优化？

1. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。
2. 选择合适的表字段类型和存储引擎，适当添加索引。
3. `MySQL`库主从读写分离。
4. 找规律分表，减少表单中的数据量，提高查询速度。
5. 添加缓存机制。可以使用`Redis`缓存。
6. 不经常改动的页面，生成静态页面。
7. 写高效率的`sql`语句。如：`SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE`。

为什么要避免使用join查询?

答：减少消耗。

### 对于大流量网站，如何解决各页面统计访问量问题？

1. 确认服务器是否能支撑当前访问量。
2. 优化数据库访问。
3. 禁止外部访问，如图片盗链。
4. 控制文件下载。
5. 使用不同主机进行分流。
6. 使用浏览统计软件，了解访问量，有针对性的进行优化。

### 如何进行`SQL`优化？


1. 选择正确的存储引擎。
每个引擎都有利有弊，比如`MyISAM`，适用于大量查询，对大量写操作并不是很好，`update`一个字段都会把整个表锁起来，而I`nnodb`，对一些小的应用，它比`MyISAM`慢，但它支持行锁，再写操作的时候，很优秀，它还支持更多的高级应用。
2. 优化字段的数据类型
一个原则，越小的越快，如果一个表只有几列，那我们就不用用`INT`来做主键，可以使用`MEDIUMINT`，`SMALLINT`或是更小的`TINYINT`会更经济一些，如果不需要记录时间，使用`DATE`要比`DATETIME`好的多，也要留够足够的空间进行扩展。
3. 为搜索字段添加索引
索引不一定只添加给主键或唯一的字段，如果在表中有某个字段经常用来做搜索，那就为它建立索引，如果要搜索的字段是大的文本字段，那应该为它建立全文索引。
4. 避免使用`select *`因为从数据库读出的数据越多，那么查询就会越慢。如果数据库服务和WEB服务器在不同的机器上的话，还会增加网络传输的负载。即使要查询表的所有字段，也尽量不要用`*`通配符。
5. 使用`ENUM`而不是`VARCHAR`
`ENUM`类型是非常快和紧凑的，它保存的是`TINYINT`，但外表上显示的是字符串，做一些选项列表很好，比如：性别，民族，部门，状态之类的字段，取值有限而且固定。
6. 尽可能使用`NOT NULL`
`NULL`其实也需要额外空间的，在进行比较的时候，程序也会变得复杂，并不是并不可以用`NULL`，在现实的复杂情况下，依然会有些情况需要使用`NULL`值。
7. 固定长度的表会更快
如果表中的所有字段都是固定长度的，那整个表会被认为是`“static”`或“`fixed-lenght”`。例如表中没有`VARCHAR`，`TEXT`，`BLOB`，只要表中其中一个字段是这些类型，那么这个表就不是“固定长度静态表”了，这样的话`MySQL`引擎会用另一种方法来处理。
固定长度的表也容易被缓存和重建，唯一的副作用就是，固定长度的字段会浪费一些空间，因为固定长度的字段无论用不用，都会分配那么多的空间。

### 如何设计一个高并发的系统


1. 数据库优化，喝的事务隔离级别，`SQL`语句，索引优化。
2. 使用缓存，尽量减少数据库`IO`操作。
3. 分布式数据库，分布式缓存。
4. 服务器负载均衡。

### 什么情况下设置了索引却无法使用


1. 以%开头`LIKE`，模糊匹配。
2. `OR`语句前后没有同时使用索引。
3. 数据类型出现隐式转化，如`varchar`不加单引号可能会转换为`int`型。

### `SQL`注入的主要特点


1. 变种极多，攻击简单，危害极大。
2. 未经授权操作数据库的数据。
3. 恶意篡改网页。
4. 网页挂木马。
5. 私自添加系统账号或是数据库使用者账号。

### 优化数据库的方法

1. 选取最适合的字段属性，尽可能减少定义字段宽度，尽量把字段设成`NOT NULL`。
2. 使用`exists`替代`in`，用`not exists`替代`not in`。
3. 使用连接`（JOIN）`来替代子查询。
4. 适用联合`（NUION）`来代替手动创建的临时表。
5. 事务处理。
6. 锁定表，优化事务处理。
7. 适当用外键，优化锁定表。
8. 建立索引。
9. 优化查询语句。

### 数据库中的事务是什么

事务作为一个单元的一组有序的数据操作，如果组中的所有操作都完成，则认定事务成功，即使只有一个失败，事务也不成功。如果所有操作完成，事务则进行提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有的操作的影响都会取消。

- `ACID`四大特性
- 原子性：不可分割，事务要么全部被执行，要么全部不执行。
- 一致性：事务的执行使得数据库从一种正确的状态转换成另一种正确的状态。
- 隔离性：在事务正确提交前，不允许把该事务对数据的任何改变提供给任何其他事务。
- 持久性：事务正确提交后，将结果永久保存到数据库中，即使在事务提交后，有了其他故障，事务处理结果也会得到保存。

### 索引的目的是什么？

1. 快速访问数据表中特定信息，提高检索速度。
2. 创建唯一性索引，保证每一行数据的唯一性。
3. 加速表和表之间的连接。
4. 使用分组和排序子句进行数据检索时，可显著的减少分组和排序的时间。

### 索引对数据库系统的负面影响是什么？
创建索引和维护索引需要消耗时间，这个时间会随着数据量的增加而增加，索引需要占用物理空间。当对表进行增删改查的时候索引也需要动态维护，这样就降低了数据的维护速度。
### 为数据表建立索引的原则

1. 频繁使用的，用以缩小查询范围的字段上建立索引。
2. 频繁使用的，需要排序的字段上建立索引。

### 什么情况下不宜建立索引

对于查询中涉及很少的列，或是重复值较多的列，不宜建立索引。

一些特殊的数据类型，不宜就建立索引。如`text`文本字段。

### 左连接和右连接的区别


左连接：

- 左连接会读取左表中的全部数据，即使右表中没有对应的数据（如果俩个表有相同的数据，只会显示一个），用`NULL`填充。

右连接：

- 右连接会读取右表的全部数据，即使左表中没有对应的数据（如果俩个表有相同的数据，只会显示一个），用`NULL`填充。

### 什么是锁？


数据库是一个多用户使用的共享资源，当多个用户并发的存取数据时，在数据库中就会产生多个事务同时存取同一个数据的情况，若对并发操作不加控制可能就会读取和储存不正确的数据，破坏数据库的一致性。

### 什么是存储过程，用什么来调用？


存储过程就是一个预编译的`SQL`语句，优点是允许模块化设计，只需要创建一次，就可以在该程序中多次调用，如果某次操作需要执行多次`SQL`，使用存储过程比单纯的`SQL`语句要快。可以使用一个命令对象进行调用。

### 索引的作用，和它的优缺点


索引就是一种特殊的查询表，数据库引擎可以用它加速对数据的检索，索引是唯一的，在创建时可以以指定单个列或是多个列。缺点是它减慢了数据录入的速度，同时也增加了数据库的尺寸大小。

### 主键，外键，索引的区别？

主键：

- 唯一标识一条记录，不可重复，不可为`NULL`。
- 用来保证数据的完整性。
- 只能有一个。

外键：

- 表的外键是另一个表的主键，外键可以重复，可以为空。
- 用来和其他表建立联系。
- 一个表可以有多个外键。

索引：

- 该字段没有重复值，可以有一个是空值。
- 提高查询效率排序速度。
- 一个表可以有多个唯一索引。

### 对`SQL`语句的优化方法
1. 避免在索引列上使用计算。
2. 避免在索引列上使用`IS NULL`和`IS NOT NULL`。
3. 对查询进行优化，尽量避免全表扫描，首先因该考虑在`where`和`order by`涉及的列上建立索引。
4. 避免在`where`子句对字段进行null值判断，这件导致引擎放弃使用索引而进行全表扫描。
5. 避免在`where`子句中对字段进行表达式操作，也会导致引擎放弃使用索引而进行全表扫描。

### `SQL`语句中“相关子查询”和“非相关子查询”有什么区别
如果你想加载一篇你写过的.md文件，在上方工具栏可以选择导入功能进行对应扩展名的文件导入，
继续你的创作。

子查询：嵌套在其他查询中的查询。

非相关子查询：

- 非相关子查询是独立于外部查询的子查询，子查询总共执行一次，执行完毕后将值传递给外部的查询。

相关子查询：

- 相关子查询的执行依赖于外部的查询数据，外部查询执行一次，子查询就会执行一次。

【所以非相关子查询比相关子查询效率高】

### `char`和`varchar`的区别

- char`类型的数据列里，每个值都占`M`个字节，如果长度小于`M`，就会在它的右边用空格字符进行补足（在检索操作中填补出来的空格符将会被去掉）。
- `vachar`类型的数据列里，每个值只占用刚好够用的字节再加上一个用来记录长度的字节，所以总长度为`L+1`字节。

### `SQL`问题

- 脏读

- 在一个事务处理过程中读取到了另一个未提交事务中的数据。

【例子】

A在一个转账事务中，转了100给B，此时B读到了这个转账的数据，然后做了一些操作（给A发货，或是其他），可是这个时候A的事务并没有提交，如果A回滚了事务，那这就是脏读。

- 不可重复读

- 对数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，是由于在查询间隔，被另一个事务修改并提交了。

【例子】

事务A在读取某一数据，而事务B立马修改了这个数据并且提交了事务到数据库，事务A再次读取就得到了不同的结果。发生了不重复读。

- 幻读

- 事务非独立执行时发生的一种现象。

【例子】

事务A对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务B又对这个表中插入了一行数据项，这个数据的数值还是“1”并且提给了数据库，如果事务A查看刚刚修改的数据，会发现还有一数据没有修改，而这行数据时事务B中添加的，就像产生的幻觉一样。发生了幻读。

### `MySQL`事务隔离级别

1. `read uncmmited`：读到未提交数据
- 最低级别，无法保证任情况
2. `read commited`：读已提交
- 可避免脏读
3. `repeatable read`：可重复读
- 可避免脏读、不可重复读
4. `serializable`：串行事务
- 可避免脏读、不可重复读、幻读

**【`MySQL`默认事务隔离级别为`Repeatable Read`（可重复读）】**

### `MySQL`临时表

什么是临时表：临时表是`MySQL`用于存储中间结果集的表，临时表只在当前连接可看，当连接关闭时会自动删除表并释放所有空间。

为什么会产生临时表：一般是因为复杂的`SQL`导致临时表被大量创建

- 进行`union`查询时
- 用到`temptable`算法或者是`union`查询中的视图
- `ORDER BY`和`GROUP BY`的子句不一样时
- 表连接中，`ORDER BY`的列不是驱动表中的
- `DISTINCT`查询并且加上`ORDER BY`时
- `SQL`中用到`SLQ_SMALL_RESULT`选项时
- `RROM`中的子查询

临时表分为俩种：

- 内存临时表
- 采用的是`memory`存储引擎
- 磁盘临时表
- 菜用的是`myisam`存储引擎

### 什么是视图，游标是什么？

视图：视图是一种虚拟表，具有和物理表相同的功能。可以对视图表进行增删改查操作，视图通常是有一个表或者多个表的子集。对视图的修改不会影响基本表。

- 【使得我们获取数据更容易，相比多表查询】

游标：是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行进行修改。

- 【一般不会使用，但需要逐条处理数据的时候，游标显得十分重要】

## redis

文章：https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md

### 一、概述

Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。

键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。

Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。

### 二、数据类型

| 数据类型 | 可以存储的值 | 操作 |
| :--: | :--: | :--: |
| STRING | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作</br> 对整数和浮点数执行自增或者自减操作 |
| LIST | 列表 | 从两端压入或者弹出元素 </br> 对单个或者多个元素进行修剪，</br> 只保留一个范围内的元素 |
| SET | 无序集合 | 添加、获取、移除单个元素</br> 检查一个元素是否存在于集合中</br> 计算交集、并集、差集</br> 从集合里面随机获取元素 |
| HASH | 包含键值对的无序散列表 | 添加、获取、移除单个键值对</br> 获取所有键值对</br> 检查某个键是否存在|
| ZSET | 有序集合 | 添加、获取、删除元素</br> 根据分值范围或者成员来获取元素</br> 计算一个键的排名 |

> [What Redis data structures look like](https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-2-what-redis-data-structures-look-like/)

#### STRING

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/6019b2db-bc3e-4408-b6d8-96025f4481d6.png" width="400"/> </div><br>

```html
> set hello world
OK
> get hello
"world"
> del hello
(integer) 1
> get hello
(nil)
```

#### LIST

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/fb327611-7e2b-4f2f-9f5b-38592d408f07.png" width="400"/> </div><br>

```html
> rpush list-key item
(integer) 1
> rpush list-key item2
(integer) 2
> rpush list-key item
(integer) 3

> lrange list-key 0 -1
1) "item"
2) "item2"
3) "item"

> lindex list-key 1
"item2"

> lpop list-key
"item"

> lrange list-key 0 -1
1) "item2"
2) "item"
```

#### SET

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/cd5fbcff-3f35-43a6-8ffa-082a93ce0f0e.png" width="400"/> </div><br>

```html
> sadd set-key item
(integer) 1
> sadd set-key item2
(integer) 1
> sadd set-key item3
(integer) 1
> sadd set-key item
(integer) 0

> smembers set-key
1) "item"
2) "item2"
3) "item3"

> sismember set-key item4
(integer) 0
> sismember set-key item
(integer) 1

> srem set-key item2
(integer) 1
> srem set-key item2
(integer) 0

> smembers set-key
1) "item"
2) "item3"
```

#### HASH

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7bd202a7-93d4-4f3a-a878-af68ae25539a.png" width="400"/> </div><br>

```html
> hset hash-key sub-key1 value1
(integer) 1
> hset hash-key sub-key2 value2
(integer) 1
> hset hash-key sub-key1 value1
(integer) 0

> hgetall hash-key
1) "sub-key1"
2) "value1"
3) "sub-key2"
4) "value2"

> hdel hash-key sub-key2
(integer) 1
> hdel hash-key sub-key2
(integer) 0

> hget hash-key sub-key1
"value1"

> hgetall hash-key
1) "sub-key1"
2) "value1"
```

#### ZSET

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1202b2d6-9469-4251-bd47-ca6034fb6116.png" width="400"/> </div><br>

```html
> zadd zset-key 728 member1
(integer) 1
> zadd zset-key 982 member0
(integer) 1
> zadd zset-key 982 member0
(integer) 0

> zrange zset-key 0 -1 withscores
1) "member1"
2) "728"
3) "member0"
4) "982"

> zrangebyscore zset-key 0 800 withscores
1) "member1"
2) "728"

> zrem zset-key member1
(integer) 1
> zrem zset-key member1
(integer) 0

> zrange zset-key 0 -1 withscores
1) "member0"
2) "982"
```

### 三、数据结构

#### 字典

dictht 是一个散列表结构，使用拉链法解决哈希冲突。

```c
/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;
```

```c
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;
```

Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。

```c
typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。

渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。

在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。

采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。

```c
/* Performs N steps of incremental rehashing. Returns 1 if there are still
 * keys to move from the old to the new hash table, otherwise 0 is returned.
 *
 * Note that a rehashing step consists in moving a bucket (that may have more
 * than one key as we use chaining) from the old to the new hash table, however
 * since part of the hash table may be composed of empty spaces, it is not
 * guaranteed that this function will rehash even a single bucket, since it
 * will visit at max N*10 empty buckets in total, otherwise the amount of
 * work it does would be unbound and the function may block for a long time. */
int dictRehash(dict *d, int n) {
    int empty_visits = n * 10; /* Max number of empty buckets to visit. */
    if (!dictIsRehashing(d)) return 0;

    while (n-- && d->ht[0].used != 0) {
        dictEntry *de, *nextde;

        /* Note that rehashidx can't overflow as we are sure there are more
         * elements because ht[0].used != 0 */
        assert(d->ht[0].size > (unsigned long) d->rehashidx);
        while (d->ht[0].table[d->rehashidx] == NULL) {
            d->rehashidx++;
            if (--empty_visits == 0) return 1;
        }
        de = d->ht[0].table[d->rehashidx];
        /* Move all the keys in this bucket from the old to the new hash HT */
        while (de) {
            uint64_t h;

            nextde = de->next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            de->next = d->ht[1].table[h];
            d->ht[1].table[h] = de;
            d->ht[0].used--;
            d->ht[1].used++;
            de = nextde;
        }
        d->ht[0].table[d->rehashidx] = NULL;
        d->rehashidx++;
    }

    /* Check if we already rehashed the whole table... */
    if (d->ht[0].used == 0) {
        zfree(d->ht[0].table);
        d->ht[0] = d->ht[1];
        _dictReset(&d->ht[1]);
        d->rehashidx = -1;
        return 0;
    }

    /* More to rehash... */
    return 1;
}
```

#### 跳跃表

是有序集合的底层实现之一。

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/beba612e-dc5b-4fc2-869d-0b23408ac90a.png" width="600px"/> </div><br>

在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0ea37ee2-c224-4c79-b895-e131c6805c40.png" width="600px"/> </div><br>

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

### 四、使用场景

#### 计数器

可以对 String 进行自增自减运算，从而实现计数器功能。

Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

#### 缓存

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

#### 查找表

例如 DNS 记录就很适合使用 Redis 进行存储。

查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

#### 消息队列

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息

不过最好使用 Kafka、RabbitMQ 等消息中间件。

#### 会话缓存

可以使用 Redis 来统一存储多台应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

#### 分布式锁实现

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。

可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

#### 其它

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

### 五、Redis 与 Memcached

两者都是非关系型内存键值数据库，主要有以下不同：

#### 数据类型

Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。

#### 数据持久化

Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。

#### 分布式

Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。

Redis Cluster 实现了分布式的支持。

#### 内存管理机制

- 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。

- Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。

### 六、键的过期时间

Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。

对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

### 七、数据淘汰策略

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

Redis 具体有 6 种淘汰策略：

| 策略 | 描述 |
| :--: | :--: |
| volatile-lru | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| volatile-ttl | 从已设置过期时间的数据集中挑选将要过期的数据淘汰 |
|volatile-random | 从已设置过期时间的数据集中任意选择数据淘汰 |
| allkeys-lru | 从所有数据集中挑选最近最少使用的数据淘汰 |
| allkeys-random | 从所有数据集中任意选择数据进行淘汰 |
| noeviction | 禁止驱逐数据 |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。

Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。

### 八、持久化

Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

#### RDB 持久化

将某个时间点的所有数据都存放到硬盘上。

可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

如果系统发生故障，将会丢失最后一次创建快照之后的数据。

如果数据量很大，保存快照的时间会很长。

#### AOF 持久化

将写命令添加到 AOF 文件（Append Only File）的末尾。

使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：

| 选项 | 同步频率 |
| :--: | :--: |
| always | 每个写命令都同步 |
| everysec | 每秒同步一次 |
| no | 让操作系统来决定何时同步 |

- always 选项会严重减低服务器的性能；
- everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
- no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

### 九、事务

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。

Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。

### 十、事件

Redis 服务器是一个事件驱动程序。

#### 文件事件

服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。

Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/9ea86eb5-000a-4281-b948-7b567bd6f1d8.png" width=""/> </div><br>

#### 时间事件

服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。

时间事件又分为：

- 定时事件：是让一段程序在指定的时间之内执行一次；
- 周期性事件：是让一段程序每隔指定时间就执行一次。

Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。

#### 事件的调度与执行

服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。

事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：

```python
def aeProcessEvents():
    # 获取到达时间离当前时间最接近的时间事件
    time_event = aeSearchNearestTimer()
    # 计算最接近的时间事件距离到达还有多少毫秒
    remaind_ms = time_event.when - unix_ts_now()
    # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0
    if remaind_ms < 0:
        remaind_ms = 0
    # 根据 remaind_ms 的值，创建 timeval
    timeval = create_timeval_with_ms(remaind_ms)
    # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定
    aeApiPoll(timeval)
    # 处理所有已产生的文件事件
    procesFileEvents()
    # 处理所有已到达的时间事件
    processTimeEvents()
```

将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：

```python
def main():
    # 初始化服务器
    init_server()
    # 一直处理事件，直到服务器关闭为止
    while server_is_not_shutdown():
        aeProcessEvents()
    # 服务器关闭，执行清理操作
    clean_server()
```

从事件处理的角度来看，服务器运行流程如下：

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/c0a9fa91-da2e-4892-8c9f-80206a6f7047.png" width="350"/> </div><br>

### 十一、复制

通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。

一个从服务器只能有一个主服务器，并且不支持主主复制。

#### 连接过程

1. 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；

2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；

3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令。

#### 主从链

随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png" width="600"/> </div><br>

### 十二、Sentinel

Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。

### 十三、分片

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0\~1000 的存储到实例 R0 中，用户 id 从 1001\~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。

### 十四、一个简单的论坛系统分析

该论坛系统功能如下：

- 可以发布文章；
- 可以对文章进行点赞；
- 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。

#### 文章信息

文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。

Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7c54de21-e2ff-402e-bc42-4037de1c1592.png" width="400"/> </div><br>

#### 点赞功能

当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。

为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/485fdf34-ccf8-4185-97c6-17374ee719a0.png" width="400"/> </div><br>

#### 对文章进行排序

为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f7d170a3-e446-4a64-ac2d-cb95028f81a8.png" width="800"/> </div><br>
----

### redis面试问题
https://cloudpai.gitee.io/2018/04/18/2018-04-18-3/
